{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preface\n",
    "Before I launch into the code I want to preface a misunderstanding I had about my data initially. I originally thought that the ` weighted_vote_score ` was a measure of the impact it had on the games review score. As it is instead a representation of the gauged helpfulness of the community, I now need to somewhat change my approach. \n",
    "Instead of focusing on attempting to guess within a range of the previous target parameter `weighted_vote_score` I'll instead need to approach it as attempting to guess 'Yes' or 'No' for whether or not they recommend the game (` voted_up `). \n",
    "\n",
    "# General Approach\n",
    "As a whole I'll need to somewhat adjust the values in my data. I'll change the boolean values into 0 or 1 respectively, and drop the language column (since it appears to be entirely english). From here I'll only include the recieved_for_free, written_during_early_acces, weighted_vote_score, and review in the algorithm. This will then be fed into the algorithm to generate a guess on the voted_up scores. \n",
    "\n",
    "# Transforming the review column\n",
    "Ultimately I need a way to perform sentiment analysis of the reviews to convert it from text into a numerical value of positivity or negativity. This in account with the other factors should (hopefully) get us a good guess of whether or not someone would recommend a game. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sebas\\AppData\\Local\\Temp\\ipykernel_7536\\1799129055.py:9: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  filtered_df['review'] = filtered_df['review'].str.replace(r'\\W+', ' ')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ids</th>\n",
       "      <th>recommendationid</th>\n",
       "      <th>voted_up</th>\n",
       "      <th>received_for_free</th>\n",
       "      <th>written_during_early_access</th>\n",
       "      <th>weighted_vote_score</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>70</td>\n",
       "      <td>115513013</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.729283</td>\n",
       "      <td>Review of Half Life Revolutionizing the indus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>70</td>\n",
       "      <td>115813617</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>A must play classic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70</td>\n",
       "      <td>115817244</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>One of the best games every created still fun ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70</td>\n",
       "      <td>115566933</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.613007</td>\n",
       "      <td>sp is pretty cool deathmatch goes crazy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>70</td>\n",
       "      <td>116146745</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>I m Kayne West and this is the Kayne best</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>70</td>\n",
       "      <td>116216878</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>70</td>\n",
       "      <td>115547553</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.537176</td>\n",
       "      <td>I ve come to make an announcement Gordon Freem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>70</td>\n",
       "      <td>115619966</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.527528</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>70</td>\n",
       "      <td>116243034</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.526959</td>\n",
       "      <td>OMFG BEST GRAPHICSSSSSSSSSSSSSS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>70</td>\n",
       "      <td>115766562</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.525862</td>\n",
       "      <td>very noice game</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ids  recommendationid  voted_up  received_for_free  \\\n",
       "0   70         115513013         1                  0   \n",
       "1   70         115813617         1                  0   \n",
       "2   70         115817244         1                  0   \n",
       "3   70         115566933         1                  0   \n",
       "4   70         116146745         1                  0   \n",
       "5   70         116216878         1                  0   \n",
       "6   70         115547553         0                  0   \n",
       "7   70         115619966         1                  0   \n",
       "8   70         116243034         1                  0   \n",
       "9   70         115766562         1                  0   \n",
       "\n",
       "   written_during_early_access  weighted_vote_score  \\\n",
       "0                            0             0.729283   \n",
       "1                            0             0.642857   \n",
       "2                            0             0.615385   \n",
       "3                            0             0.613007   \n",
       "4                            0             0.583333   \n",
       "5                            0             0.565217   \n",
       "6                            0             0.537176   \n",
       "7                            0             0.527528   \n",
       "8                            0             0.526959   \n",
       "9                            0             0.525862   \n",
       "\n",
       "                                              review  \n",
       "0   Review of Half Life Revolutionizing the indus...  \n",
       "1                               A must play classic   \n",
       "2  One of the best games every created still fun ...  \n",
       "3            sp is pretty cool deathmatch goes crazy  \n",
       "4          I m Kayne West and this is the Kayne best  \n",
       "5                                               1998  \n",
       "6  I ve come to make an announcement Gordon Freem...  \n",
       "7                                               Yes   \n",
       "8                   OMFG BEST GRAPHICSSSSSSSSSSSSSS   \n",
       "9                                    very noice game  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "base_path = Path()\n",
    "raw_data = base_path.joinpath('raw_data')\n",
    "filtered_data = 'filtered_data.json'\n",
    "\n",
    "filtered_df = pd.read_json(raw_data.joinpath(filtered_data))\n",
    "filtered_df['review'] = filtered_df['review'].str.replace(r'\\W+', ' ')\n",
    "filtered_df[['voted_up', 'received_for_free', 'written_during_early_access']] = filtered_df[['voted_up', 'received_for_free', 'written_during_early_access']].astype(int)\n",
    "filtered_df.drop(columns='language', inplace=True, axis=1)\n",
    "display(filtered_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25      80.00\n",
      "0.50     238.00\n",
      "0.75     613.00\n",
      "0.90    1347.00\n",
      "0.95    2088.35\n",
      "0.99    4310.00\n",
      "Name: review, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#We filter this to cut down on the amount I have to pad. I can capture ~90% of the data by cutting it off at 1350 characters.\n",
    "#With just slicing the first 100 reviews I was able to go from ~9min down to 30 seconds. \n",
    "#I've tried experimenting with some of the methods to speed up the process, but I haven't been able to get much to work without something else breaking.\n",
    "\n",
    "print(filtered_df['review'].apply(len).quantile([0.25, 0.5, 0.75, 0.9, 0.95, 0.99]))\n",
    "filtered_df = filtered_df.loc[filtered_df['review'].apply(len) < 1350]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis\n",
    "This portion of the process has been somewhat of a struggle. While I could use NLTK or similar libaries to maybe get a good guess at the sentiment values, I want to test if a Neural Network model can get resonably close as well. First I had to figure out how to shape the data in a way that the Neural Network would properly work with, via subclassing the Dataset class, then I had to define various methods to make the data work.\n",
    "\n",
    "Right now the Dataset takes too long to process, at least in order for me to submit the assignment in at a resonable time, however I will improve the effciency of this such that we can get a good test of the neural network benefits.\n",
    "\n",
    "After a couple days of working out the issues in the Dataset subclass, I was able to have a working model of the data to plug into the CNN Sentiment Analysis model. From what I could find CNN models worked reasonably well at learning the sentiments of datasets as well as long-term patterns. So I opted to utilize this method and implement a model to guess the data.\n",
    "\n",
    "This process took a while to get it right, but finally I was left with my current model. The inital tests with a limited selection showed to be promising whe compared to the test set - but against the total dataframe it just guessed everything as being a recommended review - which isn't ideal. At the moment I'm going to assume its from having too many unexpected tokens - resulting in poor performance, but it's hard to say until I can train it against the whole of the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchtext\n",
    "import torch.optim as optim\n",
    "from tqdm.notebook import tqdm\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "        self.tokenizer = torchtext.data.get_tokenizer('basic_english')\n",
    "        self.max_seq_len = self._infer_max_seq_len()\n",
    "        self.tokenized_data = self._tokenize_reviews()\n",
    "        self.vocab = self._build_vocab()\n",
    "        self.numericalized_data = self._numericalize_data()\n",
    "\n",
    "    def _infer_max_seq_len(self):\n",
    "        max_seq_len = 0\n",
    "        for text in self.df['review']:\n",
    "            tokens = self.tokenizer(text)\n",
    "            max_seq_len = max(max_seq_len, len(tokens))\n",
    "        return max_seq_len\n",
    "    \n",
    "    def _tokenize_reviews(self):\n",
    "        tokenized_reviews = []\n",
    "        with ThreadPoolExecutor() as executor:\n",
    "            for tokens in tqdm(executor.map(self.tokenizer, self.df['review']), desc='Tokenizing Reviews', total=len(self.df['review'])):\n",
    "                tokenized_reviews.append(tokens)\n",
    "        return tokenized_reviews\n",
    "\n",
    "    def _build_vocab(self):\n",
    "        vocab = torchtext.vocab.build_vocab_from_iterator(self.tokenized_data, specials=['<unk>', '<pad>'])\n",
    "        vocab.set_default_index(vocab['<unk>'])\n",
    "        return vocab\n",
    "\n",
    "    def _numericalize_data(self):\n",
    "            tokenized_reviews = self.tokenized_data \n",
    "            vocab_stoi_data = self.get_vocab()\n",
    "            numericalized_reviews = np.ones((len(tokenized_reviews), self.max_seq_len), dtype=np.int64)\n",
    "            for i, tokens in tqdm(enumerate(tokenized_reviews), desc='Numericalizing Tokens', total=len(tokenized_reviews)):\n",
    "                numericalized_tokens = [vocab_stoi_data[token] for token in tokens]\n",
    "                numericalized_reviews[i, :len(numericalized_tokens)] = numericalized_tokens[:self.max_seq_len]\n",
    "            return torch.from_numpy(numericalized_reviews), torch.tensor(self.df['voted_up'].values, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.numericalized_data[0])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        numericalized_review = self.numericalized_data[0][idx]\n",
    "        label = self.numericalized_data[1][idx]\n",
    "        return torch.tensor(numericalized_review), torch.tensor(label)\n",
    "\n",
    "    def get_vocab(self, index=False):\n",
    "        '''Returns the vocab object as number index if true, else as string index'''\n",
    "        return self.vocab.get_itos() if index else self.vocab.get_stoi()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.005002021789550781,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Tokenizing Reviews",
       "rate": null,
       "total": 82720,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "736e3e9069b948d7b9179c0b3b392492",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing Reviews:   0%|          | 0/82720 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.004000663757324219,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Numericalizing Tokens",
       "rate": null,
       "total": 82720,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e74b5c83ecaf48028e5f1523f9c796d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Numericalizing Tokens:   0%|          | 0/82720 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.003973960876464844,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Tokenizing Reviews",
       "rate": null,
       "total": 20681,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1ae4aea2e17407299cf474daba21288",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing Reviews:   0%|          | 0/20681 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.003998279571533203,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Numericalizing Tokens",
       "rate": null,
       "total": 20681,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d1c6b3c5052438fb67393e3626ef715",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Numericalizing Tokens:   0%|          | 0/20681 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_dataframe, test_dataframe = train_test_split(filtered_df[['review', 'voted_up']], test_size=0.2, random_state=42)\n",
    "train_data = CustomDataset(train_dataframe)\n",
    "test_data = CustomDataset(test_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unknown Index: 0 \n",
      " Pad Index: 1\n",
      "tensor([   30,   143,   179,    29,   236,   450,   372,   326,   309,   432,\n",
      "        14844, 32826,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1])\n",
      "tensor([    2,     6,    10,    21,   192,    39,   169,     9,   334, 10137,\n",
      "          547,     7,    53,     2,   139,   528,    11,     2,   139,    51,\n",
      "           18,     4,  2079,   974,     5,     2,  2623,  2749,   878,  1558,\n",
      "           33,   166,    34,    31,     3,   828,    44,    32,     9,     5,\n",
      "            7,    66,    66,   333,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sebas\\AppData\\Local\\Temp\\ipykernel_7536\\3722360226.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(numericalized_review), torch.tensor(label)\n"
     ]
    }
   ],
   "source": [
    "print(f'Unknown Index: {train_data.get_vocab()[\"<unk>\"]} \\n Pad Index: {train_data.get_vocab()[\"<pad>\"]}')\n",
    "print(train_data[0][0])\n",
    "print(test_data[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class SentimentCNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, n_filters, filter_sizes, output_dim, dropout):\n",
    "        super().__init__()\n",
    "        seed = 42\n",
    "        torch.manual_seed(seed)\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.manual_seed(seed)\n",
    "            \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.convs = nn.ModuleList([\n",
    "            nn.Conv1d(in_channels=embedding_dim,\n",
    "                      out_channels=n_filters,\n",
    "                      kernel_size=fsz)\n",
    "            for fsz in filter_sizes\n",
    "        ])\n",
    "        self.fc = nn.Linear(len(filter_sizes) * n_filters, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, text):\n",
    "        # text = [batch size, sent len]\n",
    "        embedded = self.embedding(text)\n",
    "        # embedded = [batch size, sent len, emb dim]\n",
    "        embedded = embedded.permute(0, 2, 1)  # [batch size, emb dim, sent len]\n",
    "\n",
    "        # apply convolutions and activation functions\n",
    "        conved = [F.relu(conv(embedded)) for conv in self.convs]\n",
    "\n",
    "        # pooling\n",
    "        pooled = [F.max_pool1d(conv, conv.shape[2]).squeeze(2) for conv in conved]\n",
    "\n",
    "        # concatenate pooled features and pass through the dropout layer\n",
    "        cat = self.dropout(torch.cat(pooled, dim=1))\n",
    "\n",
    "        # pass through the fully connected layer\n",
    "        out = self.fc(cat)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_loader = torch.utils.data.DataLoader(train_data, batch_size=128, shuffle=True)\n",
    "test_data_loader = torch.utils.data.DataLoader(test_data, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.003999948501586914,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Tokenizing Reviews",
       "rate": null,
       "total": 1024,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06cbd08d0f59426d8f6e83a94b06d687",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing Reviews:   0%|          | 0/1024 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.003998517990112305,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Numericalizing Tokens",
       "rate": null,
       "total": 1024,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb29d062a67843a2ae81f05372cdd762",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Numericalizing Tokens:   0%|          | 0/1024 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.03599953651428223,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Tokenizing Reviews",
       "rate": null,
       "total": 1024,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "621df57b61fb406fae0ed9f2b595d790",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing Reviews:   0%|          | 0/1024 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.007999897003173828,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Numericalizing Tokens",
       "rate": null,
       "total": 1024,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccd24de08b2242758c8203242f3d89e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Numericalizing Tokens:   0%|          | 0/1024 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tuning_train_data = CustomDataset(train_dataframe[:1024])\n",
    "tuning_test_data = CustomDataset(test_dataframe[:1024])\n",
    "tuning_train_data_loader = torch.utils.data.DataLoader(tuning_train_data, batch_size=32, shuffle=True)\n",
    "tuning_test_data_loader = torch.utils.data.DataLoader(tuning_test_data, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.0050046443939208984,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9e5edc540d9478bbfdb4baecadc002f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sebas\\AppData\\Local\\Temp\\ipykernel_7536\\3722360226.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(numericalized_review), torch.tensor(label)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEGCAYAAAB/+QKOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/P9b71AAAACXBIWXMAAAsTAAALEwEAmpwYAAAs10lEQVR4nO3de1zUdb4/8BczDPfLICjocBsBFdO8JKipWWqiGWppRlqauWxaVltbYbZnT3bOnrVad+u0q79yt9121w5rtSZW3i9pCTbKoIOAzAByGUAYQAYFuX5+f2CzsYyKwtcvMK/n4/F+yMx8vzPvD8vOq+/38704ARAgIiL6Nwq5GyAiot6JAUFERHYxIIiIyC4GBBER2cWAICIiu5zlbqCnVFRUoLCwUO42iIj6lLCwMAwaNMjua/0mIAoLCxETEyN3G0REfYpOp7vma9zFREREdjEgiIjILgYEERHZxYAgIiK7GBBERGQXA4KIiOxiQBARkV0OHxBuXp6YvfophIwaKXcrRES9iqQBERcXh5ycHBiNRiQlJXV6/emnn8aZM2eg1+tx7NgxREdHA2g/s6++vh56vR56vR5btmyRrEcnhQJxzyZi6Pgxkn0GEVFfJaQohUIhTCaT0Gq1QqVSiYyMDBEdHd1hGW9vb9vP8fHxYvfu3QKACAsLEwaD4aY+T6fT3XKvG08eEfE/f06S3wOLxWL15rred6dkWxCxsbEwmUwoKChAc3MzkpOTsWDBgg7L1NXV2X729PSEEEKqdq7LWlkFn4H+snw2EVFvJVlAaDQaFBcX2x6XlJRAo9F0Wu6ZZ56ByWTC22+/jeeff972vFarRXp6Oo4cOYKpU6fa/YzExETodDrodDoEBATccq91lip4+zMgiIh+TPZJ6s2bNyMyMhJJSUn4xS9+AQAoKytDaGgoxo8fj5deegmffPIJvL29O627detWxMTEICYmBhaL5ZZ7sFZa4M0tCCKiDiQLCLPZjJCQENvj4OBgmM3may6fnJyMhQsXAgCamppQXV0NAEhPT0deXh6GDRsmVauwWriLiYjo30kWEDqdDlFRUQgPD4dKpUJCQgJSUlI6LBMZGWn7ed68eTAajQCAgIAAKBTtrWm1WkRFRSE/P1+qVmGttMDDxwfOrq6SfQYRUV8j2f0gWltbsXbtWuzduxdKpRIfffQRsrKysGHDBpw8eRK7du3C2rVrMWvWLDQ3N6OmpgYrVqwAANxzzz1488030dzcjLa2NqxevRo1NTVStYq6yioAgE/AAFSbyyT7HCKivkb2w6x6orpzmOuIqZPEJkOqCB8zWvZxsFgs1u0sWQ5z7UvqLO3zHZyoJiL6FwYE2ucgAMBn4K0fKktE1N8wIABcqrmIttZW+ARwC4KI6AcMCACirQ11VdXcgiAi+hEGxFVWSxW8AwbI3QYRUa/BgLiqrrIKPt24XAcRUX/DgLiKl9sgIuqIAXGV1VIFrwF+UCiVcrdCRNQrMCCuslZaoFAo4DXAT+5WiIh6BQbEVXWWq5fb4G4mIiIADAibH06W8+ZENRERAAaEzQ+X2+AWBBFROwbEVVbbLiZuQRARAQwIm9bmZly+WMvLbRARXcWA+BFrpYW7mIiIrmJA/EidpQre/gwIIiKAAdGBtbKKZ1MTEV3FgPgRq8XCOQgioqsYED9irayCs4sLPHx95G6FiEh2DIgfqeOd5YiIbBgQP2Ll5TaIiGwkDYi4uDjk5OTAaDQiKSmp0+tPP/00zpw5A71ej2PHjiE6Otr22rp162A0GpGTk4PZs2dL2aYNL7dBRNSRkKIUCoUwmUxCq9UKlUolMjIyRHR0dIdlvL29bT/Hx8eL3bt3CwAiOjpaZGRkCBcXFxEeHi5MJpNQKBTX/TydTtftnl3c3cUmQ6q476nHJfmdsFgsVm+r6313SrYFERsbC5PJhIKCAjQ3NyM5ORkLFizosExdXZ3tZ09PTwghAAALFixAcnIympqacP78eZhMJsTGxkrVqk1TQwMa6+t5ZzkiIgDOUr2xRqNBcXGx7XFJSQkmTpzYablnnnkGL730ElxcXDBjxgzbumlpaR3W1Wg0ndZNTEzET3/6UwBAQA99qVsrqzgHQUSEXjBJvXnzZkRGRiIpKQm/+MUvbmrdrVu3IiYmBjExMbBYLD3Sj9VigTfPhSAiki4gzGYzQkJCbI+Dg4NhNpuvuXxycjIWLlx4S+v2pLrKKp4sR0QECQNCp9MhKioK4eHhUKlUSEhIQEpKSodlIiMjbT/PmzcPRqMRAJCSkoKEhAS4uLggPDwcUVFR+P7776VqtQNeboOIqJ1kcxCtra1Yu3Yt9u7dC6VSiY8++ghZWVnYsGEDTp48iV27dmHt2rWYNWsWmpubUVNTgxUrVgAAsrKysH37dmRlZaGlpQXPPvss2trapGq1A6vFAjdPT7i4u6OpoeG2fCYRUW8l+2FWPVE9cZgrAHFX/FyxyZAqAkKDZR8Ti8ViSV2yHObaV9VZeLkNIiKgFxzF1NtYK69eboMT1UTk4BgQ/8Z2uQ1uQRCRg2NA/Jv6Witampp4shwROTwGhB1WSxUvt0FEDo8BYUedpZpbEETk8BgQdtTxchtERAwIe6y83AYREQPCHqulCp5+aiidJTvRnIio12NA2PGvO8txK4KIHBcDwg7byXKcqCYiB8aAsIOX2yAiYkDY9cMWBHcxEZEjY0DYcam6Bm1tbdyCICKHxoCwo621FZeqa3ioKxE5NAbENdRVVnELgogcGgPiGqwWC7wDBsjdBhGRbBgQ11BnqeYF+4jIoTEgrsFaaYGXvx+cFPwVEZFj4rffNVgtVVA6O8PTz1fuVoiIZCFpQMTFxSEnJwdGoxFJSUmdXn/xxRdx9uxZnD59GgcOHEBoaKjttZaWFuj1euj1euzcuVPKNu364XIb3M1ERI5MSFEKhUKYTCah1WqFSqUSGRkZIjo6usMy9957r3B3dxcAxOrVq0VycrLttbq6upv6PJ1O16P9h48ZLTYZUsWIqZMk+f2wWCxWb6jrfXdKtgURGxsLk8mEgoICNDc3Izk5GQsWLOiwzJEjR9DQ0AAASEtLQ3BwsFTt3DSrhVsQROTYJAsIjUaD4uJi2+OSkhJoNJprLr9q1Srs3r3b9tjNzQ06nQ6pqamdguUHiYmJ0Ol00Ol0COjhL3Lb5TZ4wT4iclC94oYHy5Ytw4QJEzB9+nTbc2FhYSgtLYVWq8WhQ4dgMBiQn5/fYb2tW7di69atAACdTtejPbU0NaHeauXJckTksCTbgjCbzQgJCbE9Dg4Ohtls7rTczJkz8frrr2P+/PloamqyPV9aWgoAKCgowJEjRzBu3DipWr2mmtJy+AcPue2fS0TUG0gWEDqdDlFRUQgPD4dKpUJCQgJSUlI6LDN27Fh88MEHmD9/PiorK23Pq9VquLi4AAD8/f0xZcoUZGVlSdXqNZWb8hEUOfS2fy4RUW8gWUC0trZi7dq12Lt3L7Kzs7F9+3ZkZWVhw4YNiI+PBwC888478PLywqefftrhcNbo6GicPHkSGRkZOHz4MDZu3Ijs7GypWr2mMmMe/AYHwc3b67Z/NhFRbyD7YVY9UT19mCsAET3tbrHJkCrCx94p+/hYLBZLipLlMNf+oNzUPikeFMXdTETkeBgQ11FTVo4rly5jcFSE3K0QEd12DIgb4EQ1ETkqBsQNlJnyMJgBQUQOiAFxA+XGfHj6qeHtz5sHEZFjYUDcQJkxDwAweBjnIYjIsTAgbsB2JFMkA4KIHAsD4gYu11xEXVU1J6qJyOEwILqgzJjHQ12JyOEwILqg3JiPwAgtnJyc5G6FiOi2YUB0QbkpD64e7vDTDJa7FSKi24YB0QW2I5m4m4mIHAgDogsu5J0HAE5UE5FDYUB0QWN9PapKSnlGNRE5FAZEF5Wb8hHEXUxE5EAYEF1UZszDoPAwKJ17xW28iYgkx4DoonJTPpQqZwwMD5W7FSKi24IB0UXlpvYjmThRTUSOggHRRRX5hWhtbuGhrkTkMBgQXdTa0oLKwiLefpSIHAYD4ibw7nJE5EgkDYi4uDjk5OTAaDQiKSmp0+svvvgizp49i9OnT+PAgQMIDf3XBPDy5cuRm5uL3NxcLF++XMo2u6zMlI+AkGC4uLvJ3QoR0W0hpCiFQiFMJpPQarVCpVKJjIwMER0d3WGZe++9V7i7uwsAYvXq1SI5OVkAEH5+fiIvL0/4+fkJtVot8vLyhFqtvu7n6XQ6Scbx4xo14x6xyZAqQkaNlPyzWCwW63bU9b47u7QF4eHhYbuSaVRUFOLj4+F8g/MBYmNjYTKZUFBQgObmZiQnJ2PBggUdljly5AgaGhoAAGlpaQgODgbQvuWxf/9+1NTU4OLFi9i/fz/mzJnTlVYlVWZsv3kQz6gmIkfQpYA4evQo3NzcMGTIEOzbtw9PPPEE/vKXv1x3HY1Gg+LiYtvjkpISaDSaay6/atUq7N69+6bWTUxMhE6ng06nQ0BAQFeG0i3V5lI0NVzhRDUROYQuBYSTkxMaGhrw8MMPY/PmzViyZAnuuOOOHmti2bJlmDBhAt55552bWm/r1q2IiYlBTEwMLBZLj/VzLaKtDeV5+TzUlYgcQpcDYtKkSVi2bBm++uorAIBSqbzuOmazGSEhIbbHwcHBMJvNnZabOXMmXn/9dcyfPx9NTU03ta4ceCQTETmSG05i3HPPPWLnzp3i1VdfFQCEVqsV77333nXXUSqVIi8vT4SHh9smqUeO7Di5O3bsWGEymURkZGSH5/38/ER+fr5Qq9VCrVaL/Px84efnd8sTLT1Z05c/JjYZUoWn2lf2ySUWi8Xqbt3gu/Pm3szJyUl4e3t3adm5c+eKc+fOCZPJJNavXy8AiA0bNoj4+HgBQOzfv1+Ul5cLvV4v9Hq92Llzp23dlStXCqPRKIxGo3jyySe7O8geq2GTY8UmQ6qImDBO9v9hWSwWq7vV7YDYtm2b8Pb2Fh4eHuLs2bOiuLhYvPzyy7IP7CYG2WPlMzBAbDKkiimPLZZ9zCwWi9Xd6vZhriNHjkRdXR0WLlyI3bt3Q6vV4oknnujKqv2OtdKC+lor5yGIqN/rUkCoVCo4Oztj4cKFSElJQUtLC4QQUvfWa5WZ8ngkExH1e10KiA8++ADnz5+Hp6cnjh49itDQUFitVql767XM2bkYMjwKihscyUVE1Jd1KSDef/99BAcHY968eQCAoqIi3HfffZI21psVZ2bB1cMdg4aGy90KEZFkuhQQPj4+2LRpk+2s5d/85jfw9PSUurdeq8iQBQAIGz1S5k6IiKTTpYD46KOPUFdXhyVLlmDJkiWwWq3485//LHVvvZalqAT1VitCGBBE1I9d/4p7V0VERGDx4sW2x2+++Sb0er1kTfUFxYYshI5iQBBR/9WlLYiGhgZMmTLF9vjuu++2XYXVURUashAUOZT3hiCifqtLWxCrV6/GX//6V/j6+gIAampqsGLFCkkb6+2KDFlQOjtDEz0cBemn5W6HiKjHdWkL4syZMxg7dizuvPNO3HnnnRg/fjxmzJghdW+9WvHZ9olq7mYiov7qpm45WldXh7q6OgDASy+9JElDfcWlqhpUm8sQyolqIuqnbvme1D/cYc6RFRnOIoRbEETUT91yQDjypTZ+UGTIgn/wEHgN8JO7FSKiHnfdSWqr1Wo3CJycnODu7i5ZU31FUWb7PETIqJHIPvqdzN0QEfWs6waEj4/P7eqjTzJnn0NrSwtCRzMgiKj/ueVdTAQ0NVxBuSmfRzIRUb/EgOimoswsHslERP0SA6Kbig1Z8PD1QUBosNytEBH1KAZEN/0wUc2tCCLqbxgQ3VRuKkBjfT3PhyCifkfSgIiLi0NOTg6MRiOSkpI6vT5t2jScOnUKzc3NWLRoUYfXWlpaoNfrodfrsXPnTinb7BbR1oaSrHMIG32H3K0QEfWoLl2s71YoFAr84Q9/wP3334+SkhLodDqkpKQgOzvbtkxRURGefPJJvPzyy53Wb2howLhx46Rqr0cVGbIwbdkjUDo7o7WlRe52iIh6hGRbELGxsTCZTCgoKEBzczOSk5OxYMGCDssUFhbCYDCgra1NqjZui6LMLDi7uGDwsEi5WyEi6jGSBYRGo0FxcbHtcUlJCTQaTZfXd3Nzg06nQ2pqaqdg+UFiYqLtNqgBAQHd7vlWFZ05C4AT1UTUv/TaSeqwsDDExMRg6dKlePfddzF06NBOy2zduhUxMTGIiYmBxWKRoct2F8svwGqpQijnIYioH5EsIMxmM0JCQmyPg4ODYTabu7x+aWkpAKCgoABHjhzp9fMRxQaeMEdE/YtkAaHT6RAVFYXw8HCoVCokJCQgJSWlS+uq1Wq4uLgAAPz9/TFlyhRkZWVJ1WqPKMrMQuDQcLh5ecrdChFRj5AsIFpbW7F27Vrs3bsX2dnZ2L59O7KysrBhwwbEx8cDACZMmIDi4mI88sgj+OCDD5CZmQkAiI6OxsmTJ5GRkYHDhw9j48aNHY5+6o2KDFev7HpHtMydEBH1HNEfSqfTyfr57j7eYpMhVcz8yQrZfxcsFovV1bred2evnaTuaxqsdagoKEToaG5BEFH/wIDoQe1XduWRTETUPzAgelDh6Uz4DAzglV2JqF9gQPSgnO/SAADR0+6WuRMiou5jQPSg6pJSXMg/j+hpk+VuhYio2xgQPSz72HFExIyHi7u73K0QEXULA6KH5RxLhbOLC6Im3iV3K0RE3cKA6GH5pzJw5fJljOA8BBH1cQyIHtba0oLcVB1G3sOAIKK+jQEhgeyjx6EOCkRQVITcrRAR3TIGhARyvk0FAG5FEFGfxoCQgLXSgpKscxjBw12JqA9jQEgk+9vjCB8zGu4+3nK3QkR0SxgQEsk+ehxKZ2cMnxwrdytERLeEASGRIkMWLl+sRfQ9U+RuhYjoljAgJCLa2nDuuzSMmDoJTk5OcrdDRHTTGBASyjp6HF4D/BDMu8wRUR/EgJDQue/S0NbaysNdiahPYkBIqL7WisIzZ3m4KxH1SQwIiWUfO47QUSPh7T9A7laIiG4KA0Ji2UePAwBGTJ0kcydERDdH0oCIi4tDTk4OjEYjkpKSOr0+bdo0nDp1Cs3NzVi0aFGH15YvX47c3Fzk5uZi+fLlUrYpqdJzRtReqOThrkTUJwkpSqFQCJPJJLRarVCpVCIjI0NER0d3WCYsLEyMHj1afPzxx2LRokW25/38/EReXp7w8/MTarVa5OXlCbVafd3P0+l0koyjJ+qR/1wn/vv4fqFwVsreC4vFYv24rvfdKdkWRGxsLEwmEwoKCtDc3Izk5GQsWLCgwzKFhYUwGAxoa2vr8HxcXBz279+PmpoaXLx4Efv378ecOXOkalVy2cdS4e7theipnKwmor5DsoDQaDQoLi62PS4pKYFGo+nRdRMTE6HT6aDT6RAQEND9piWSffQ7VBYW44EX1kChVMrdDhFRl/TpSeqtW7ciJiYGMTExsFgscrdzTa0tLfjqd39AUORQxD4cL3c7RERdIllAmM1mhISE2B4HBwfDbDZLvm5vZTj4DfJO6THn2US4enrI3Q4R0Q1JFhA6nQ5RUVEIDw+HSqVCQkICUlJSurTu3r17MXv2bKjVaqjVasyePRt79+6VqtXbZtc778PbfwBmPPWE3K0QEXWJZLPjc+fOFefOnRMmk0msX79eABAbNmwQ8fHxAoCYMGGCKC4uFpcuXRIWi0VkZmba1l25cqUwGo3CaDSKJ598slsz8b2plm18Q2zUHRHqwEGy98JisVg3+O6Uv8HbMMheU36Dg8TGk0fEY//zS9l7YbFYLFkOcyX7asrKcfRv/8CE+LkIHjlC7naIiK6JASGDg3/8GHVV1Zj/yvNyt0JEdE0MCBk0Xq7H3s1/RMSEcRg14x652yEisosBIZMTn6egPK8AD774LJTOznK3Q0TUCQNCJm2trfhy0+8xMDwU8158Ru52iIg6YUDIKPvYcXz7f59h+vLHsOSN13gZDiLqVbhvQ2Y7/mcT6i/WYvaaVfBQ++Lvr/4SLU1NcrdFRMQtiN5g7+Y/YsevN2H0zOlI3PJbXoqDiHoFBkQv8e0nn+HvSf8J7bgxeOajzfDy95O7JSJycAyIXkT/9T589PwrGKQNw9qPP8AAzWC5WyIiB8aA6GVyvk3D/0t8Dp5qXzz1/jtQqlRyt0REDooB0QsVns7EttfewOCoCNz/9Eq52yEiB8WA6KVyjqVCt/MrzFj1BDTRw+Ruh4gcEAOiF9v59nu4VF2DhP/6Bc+2JqLbjgHRizVY6/DZm29jyPAozExcIXc7RORgGBC9XNY33+Lkrt2YlfgkBg+LlLsdInIgDIg+4IuN7+JybS0e++//gMKZl+MgotuDAdEHNFit+Py/3oYmehhmrFoudztE5CAYEH1E5qGjSP96H+5/eiWCoiLkboeIHAADog/54te/RYO1Dk/979uY9vij8PRTy90SEfVjkgZEXFwccnJyYDQakZSU1Ol1FxcXJCcnw2g0Ii0tDWFhYQCAsLAw1NfXQ6/XQ6/XY8uWLVK22WdcvliLv/78dVyuuYiFST/DLw+mYPmmX2HEtMm8VDgRSUJIUQqFQphMJqHVaoVKpRIZGRkiOjq6wzJr1qwRW7ZsEQDEo48+KpKTkwUAERYWJgwGw019nk6nk2QcvbWCoiLE/FeeFxu++VpsMqSKXx5MEXOfe1p4qn1l743FYvWdusF3pzQfOmnSJLFnzx7b43Xr1ol169Z1WGbPnj1i0qRJAoBQKpWisrJSAAyImymls7MYNWO6eOr9d8Q7Gd+KX6UeELOeXilc3N1l743FYvX+ut53p2S7mDQaDYqLi22PS0pKoNForrlMa2sramtr4e/vDwDQarVIT0/HkSNHMHXqVLufkZiYCJ1OB51Oh4CAAIlG0ru1trQg89A3+Oi5V/Cbhx9HbpoOc9f+FOt3f4apSxfzYn9EdMt65SR1WVkZQkNDMX78eLz00kv45JNP4O3t3Wm5rVu3IiYmBjExMbBYLDJ02rtcyD+Pj198De8tXYULeQV46LWfIyklGXfFz+2RoHB2cYHPQMcMYiJHJFlAmM1mhISE2B4HBwfDbDZfcxmlUglfX19UVVWhqakJ1dXVAID09HTk5eVh2DBesK6rigxZ2LJqLT746QtosNZh6f/8Ehu++RrLNr6B0bPuhYu7202/5+Bhkfj5Z3/F+q8/Q2TsXRJ0TUS9jWRXgNPpdIiKikJ4eDjMZjMSEhKwdOnSDsukpKRgxYoVSEtLw+LFi3Ho0CEAQEBAAKqrq9HW1gatVouoqCjk5+dL1Wq/lZv6PYxpOgyfMhF33j8Do+6bhvHz4tDUcAU536XBcPAIzh46hsb6+uu+z5SERYh/+TnU11pRXVqGp95/B1tX/wwF+jO3aSREJBfJJj/mzp0rzp07J0wmk1i/fr0AIDZs2CDi4+MFAOHq6iq2b98ujEajOHHihNBqtQKAePjhh0VmZqbQ6/Xi1KlT4sEHH+zWRAvr6oSTUikiYsaLh157SfzyQIrYZEgVv0o7IB5+/WURFDm00/LuPj5ixe9+LTYZUsVPNm8Snn5q4e0/QCSlJItfpR4QIaNGyj4mFovVvbred6fT1R/6PJ1Oh5iYGLnb6DOcnJwQNmY0Ji1egLFzZkLl6oq8k3ocT/4choPfIGTUSCx76w34DAzAV+9uxrG//QNCtP+p+AYOxLN/2QJ3H29seWotSs8ZZR4NEd2q6313MiAInmpfxCx8EHc/+hD8gzWoq6qGh68PasrK8fdXfonis9md1vEbEoRn/7IFLm5u+MPKZ3Ahr0CGzomouxgQ1CVOTk4YPmUiJi5agEvVNfjyt79H4+Vrz0/4hwTj2b9shpNCgT88uQaWwuJrLktEvRMDgiQzSBuGZ/68GaKtDd9/8RVyj5/A+dOZaG1ulrs1IuoCBgRJKigqAg+v/znCx4yGUuWMxvoG5J1MR+7x75Gb+j0sxeYuBYbKzRU+AQFoa23FxfILtjmPa3F2cUFgRDjUgYNg+j79hkdj/dDrtKWPoLG+Hse37+BWjwNQOCuhcnW97tawI2NA0G3h6umByJjxGHb3RAyfHIuB4aG21xrqLuFyzUVcqq7BpZoaXK6+CJWbK7wD/OEzMAA+Af5w9/nXyZDNVxphKS5BRUEhKs8XobKwGFcuXUJghBZDhkUiKCoCA8NCbPfqvnL5Mk7t2oPj23eg3JjXqbfQO+/ArJ+swB33TUNjfT2UKhWcVSqcO34C3yV/juyjx9HW2tpjvws3by+0Njej+Upjj70n3TyVmyue/vB/ERgRjr/87DXk6dLlbqnXYUCQLPyGBCEyZjx8Bg2E1wC/TtV85QqslVWwVlpQZ6lCbYUFdRYLFM7OGBgWikHhoRgYHgr/YA2Uqn+dsmMpLkFZbh7Kck0ozTWhwVqHCfPnYuycWe1HY53SI/UfO3DmwBEMvWssZv5kOaImTsDli7U4tm07vv3kMyhVSkxatACTH1kIdVAgqkvLkPbpTpzYkYJLVTW3PGY3by/c//RKTF36CBRKJapLSlFuykOZKR8XTAUoM+WjouA82lq6H0Yu7m5oarjS7ffprxRKJZ58dyOi77kbNaXlUAcOwmdvvoXvv/hS7tZ6FQYE9WkKZyUGaIbA3dsbFfnnr7krycPXB7ELH8TkRx9CQEgwmhquwMXdDbUVlTjy8SdI+3QnmhoaOr63Uok77p2KKQmLETVpAlpbWpCnS0fGngMwHPwG9bXWrvWoVGLiovmY82wiPNS+OLnza9SUlSMociiCIociIDTYtrVTW1GJ49t3IO3TL3Cp+ubCKCA0GHfefx9Gz7oXoaNGojgrB6nbd0D/9f5OY+tJzi4u8PD1aS+1L1zd3ZF3Ui/pZ3bXo2++jtiHHsRnb74N/e59WP6b/8bwKZNw6KO/4et3t9xwF6ajYECQQ3FycsKwybEYEzcTRYaz0O38uktzIIO0YbjrwTkYO2cWAkKD0drSAmPaSZzeexBZR7+75pf5sMkxmP/KCxgcFYG8k3rsfOtdmHNyOyyjVKkwSBuKwcMiMX5eHKKnTkZLUxP0u/fj2LbtMGfn2n1vhVKJwIhwjJ55L+68/z4Mvno3wSJDFky6U4iedjcGR0XgyqXLOPXlHqR++gXKck0d3sPV0wMDNIPhN3gwLtXUoOjM2Rv+LnwGDcS0pYsxJm4WvAb4wdXDvdMytRcq8eXvfo/0r/bd8P1ut7nPr8asxBXYt+VP2Lv5jwDaf5cL172IKQmLcObAEfzf+g39YgtM5eYKn4EDUVVcckvrMyCIbpJmxDCMiZuJsXNmwj+4/SrELc3NqK+1ov5iLS7X1uJyTS3cvbwQNWkCqkrM2LXp9zAcONKl9x+kDcOUxxYjZsEDcPXwQP6pDGQfS4W3/wD4Bg6EOigQ6sBB8A4YAIVSiba2NhToT8Ow/wgMB7/BxfILtvcKHzMak5c8hDFxM6BydUXh6UzUVVfDb3AQ/IYEwcPHp8NnW4pKcHLXbpz6cg+qS0o7vDZ4WASmL1+K8Q/MhpPCCdlHj6OyqBj1F62or7Xicm0tGmqtUDg7Y86ziQgdPRIF6aex49e/7RSKN+IbOBBDhg+Dz0B/XCyvQE1pGapLy9HS2L15m6lLH8FDr72E1E+/wGdvvtXp9WnLlmD+K8/DfM6Ij9a+Amtl1y70GTJqJMbNnYWKgkKcTNmNlqamG66jcnPFgCGDcbm2FvW11h7ZtfgD7wB/THlsEe5+5CFUmUvx3mOrbul9GBBE3RA8cgQiY8bD088XHr6+8FD7wlPtCw9fH6jcXJH22U4c+/v2Ln1h/Ds3L0/EPhSPKY8tQkBIMK5cvoyL5RWovVBh+7eqpBQ536XecG7E3ccHE+bPRcyCB6BQKlFTVo6a0nLUlJahprQc1WXlGBQehgnxcxEROx4KhQL5pzJwctduWCssmPb4Egy/eyIa6+tx4p+7cGzb9k4B8mNOTk6IWTAPD/xsDTz91Ej7bCf2vP8BLl+stS2jVKng7T8A3gH+GBgWjCHDh0EzIgpDhkfBa4Cf3fe1VlpQXVqGi+UVaGtp6fS6EAIV54tQdOYsijKzcKXuku21sXEzseztN3H28DF8/NJ6iLY2u58RPe1uPP7Om2hpbILh0Dc4920ajCdO4sqlyx2Wc/XwwPh5cZj8yEJoooehtaUFSmdn1FVV49v/+wzHkz+3uxsyfMxoxCych7FzZsHNy9P2fL3VivqLVlyuuYi66mqUmwpQds6I0lwTLEUlXTpQQjNiGO55IgFj586CQqnE2cPHcPRvycg/lXHDde1hQBD1ck5OTnBxd+/Sobo9QR0UiPHz4jBh/lwEDg0H0D438u0nnyL10y/QYK3r8nu5eXth9ppVmPrYYjTW18Ocndt+dFqAPzx8O269NDc2osyYh9IcI0rPGWHOMaL2QgV8AwdhgCYIfkMGw18zBH6awVAHDoKTovMFp5XOzlAPDoTi6msX8s+jyHAWlmIz7n96JQrPZOLDp1+84ZbI4GERiHsmEVETJ8DNyxOtLS0oPJ2Jc8dPoCQrB6NmTsf4B2bD1cMD5pxcpH76BdK/2ovgkSNw75NLMfKeKWhquILvv/gSR/+ajObGxqsBPQ+DtGForK/H6X2HYDxxEm6envD0U8NT7Wv713fQQAwMC7UdgNHc2IjyvAKUG/NQb61D85VGNDc2oqWxCc2NjRBtbRgzewYiY++yhfi32z5FVYn5uuO8EQYEEV1T8MgRUAcNQvbR42i181/sXRU4NBwPvLAann5+7UemVVWjzlKFOksVrJVVqCkrR0VBYY8cTuzm5YmQUSMROnokwu4chdDRI+HtPwCluSb84ck1HbYqbkThrET4mNEYfvdEDJ86CSEjRwAAmhquIGPPAaR+ugNFhqzO443QYvryx3DXg3G2e8IrlErkn8rA9198iTP7Dt8w8JUqFQKHhmPwsEgMGRaJwcMiEBQxFK5eHlC5uHY4eg8AasrK8e22T5H2z5SbGuP1MCCIqN9TBwXCarF0ez+/1wA/BI8cjvOnM7v0Jewd4I/JjyyEk0KBU7t2w1J0a5PF9iiUSji7uEDl5gqViwuslqoePV8HYEAQEdE1XO+7s1fecpSIiOTHgCAiIrsYEEREZBcDgoiI7GJAEBGRXQwIIiKyiwFBRER2MSCIiMiufnOiXEVFBQoLC6+7TEBAACyWrl25sb9x1LFz3I6F4755YWFhGDRo0DVfF45SOp1O9h44do6b4+a4+8q4uYuJiIjsYkAQEZFdDhUQH374odwtyMZRx85xOxaOu2f1m0lqIiLqWQ61BUFERF3HgCAiIrscJiDi4uKQk5MDo9GIpKQkuduRzJ/+9CdcuHABBoPB9pyfnx/27duH3Nxc7Nu3D2q1Wr4GJRIcHIxDhw7h7NmzyMzMxPPPPw+g/4/d1dUVJ06cQEZGBjIzM/HGG28AAMLDw5GWlgaj0Yjk5GSoVCp5G5WIQqFAeno6du3aBcBxxl1QUIAzZ85Ar9dDp9MBkO5vXfZjeKUuhUIhTCaT0Gq1QqVSiYyMDBEdHS17X1LUtGnTxLhx44TBYLA999Zbb4mkpCQBQCQlJYmNGzfK3mdPV1BQkBg3bpwAILy8vMS5c+dEdHS0Q4zd09NTABDOzs4iLS1NTJw4UfzjH/8Qjz76qAAgtmzZIlavXi17n1LUiy++KLZt2yZ27dolADjMuAsKCoS/v3+H5yT6W5d/sFLXpEmTxJ49e2yP161bJ9atWyd7X1JVWFhYh4DIyckRQUFBAmj/Is3JyZG9R6nriy++ELNmzXKosbu7u4tTp06J2NhYUVlZKZRKpQA6//33l9JoNOLAgQPivvvuswWEI4wbsB8QUvytO8QuJo1Gg+LiYtvjkpISaDQaGTu6vQIDA1FeXg4AKC8vR2BgoMwdSSssLAzjxo3DiRMnHGLsCoUCer0eFRUV2L9/P/Ly8nDx4kW0Xr25fX/9e3/33Xfx6quvoq2tDQDg7+/vEOMGACEE9u3bh5MnTyIxMRGANP8/d+72O1CfI4SQuwXJeHp64vPPP8fPfvYz1NXVdXq9P469ra0N48aNg6+vL3bs2IERI0bI3ZLk5s2bh4qKCqSnp2P69Olyt3PbTZ06FaWlpRg4cCD279+PnJycTsv0xN+6QwSE2WxGSEiI7XFwcDDMZrOMHd1eFy5cQFBQEMrLyxEUFISKigq5W5KEs7MzPv/8c2zbtg07duwA4DhjB4Da2locPnwYkydPhlqthlKpRGtra7/8e58yZQrmz5+PBx54AG5ubvDx8cF7773X78f9g9LSUgBAZWUlduzYgdjYWEn+1h1iF5NOp0NUVBTCw8OhUqmQkJCAlJQUudu6bVJSUrBixQoAwIoVK7Bz506ZO5LGn/70J2RnZ+N3v/ud7bn+PvaAgAD4+voCANzc3HD//fcjOzsbhw8fxuLFiwH0z3GvX78eISEh0Gq1SEhIwKFDh/D444/3+3EDgIeHB7y8vGw/z549G5mZmZL9rcs+4XI7au7cueLcuXPCZDKJ9evXy96PVPXJJ5+I0tJS0dTUJIqLi8VTTz0lBgwYIA4cOCByc3PF/v37hZ+fn+x99nRNmTJFCCHE6dOnhV6vF3q9XsydO7ffj3306NEiPT1dnD59WhgMBvEf//EfAoDQarXixIkTwmg0iu3btwsXFxfZe5Wqpk+fbpukdoRxa7VakZGRITIyMkRmZqbt+0yKv3VeaoOIiOxyiF1MRER08xgQRERkFwOCiIjsYkAQEZFdDAgiIrKLAUF0E1paWqDX623Vk1cGDgsL63AVXiK5OcSZ1EQ9paGhAePGjZO7DaLbglsQRD2goKAAb731Fs6cOYMTJ04gIiICQPtWwcGDB3H69GkcOHDAdsmXQYMG4Z///CcyMjKQkZGByZMnAwCUSiU+/PBDZGZmYu/evXBzc5NtTERALzgzkMXqK9XS0mI7U1uv14slS5YIoP3yyz+c0frEE0/YzuxNSUkRy5cvFwDEypUrxY4dOwQAkZycLF544QUBtN+vxMfHR4SFhYnm5mYxZswYAbTf22DZsmWyj5nl0CV7AyxWn6m6ujq7zxcUFAitViuA9hv3WCwWAbTfn8DZ2dn2fGVlpQAgKioqOl0GIiwsTOTm5toev/rqq+L111+Xfcwsxy3uYiLqIT++vPKtXmq5sbHR9nNrayucnTlNSPJhQBD1kEcffdT2b2pqKgDg+PHjSEhIAAAsW7YMx44dAwAcPHgQa9asAdB+wx8fHx8ZOia6Pv7nCdFNcHd3h16vtz3es2cPXnvtNQDtN40/ffo0Ghsb8dhjjwEAnnvuOfz5z3/GK6+8gsrKSqxcuRIA8MILL+DDDz/EqlWr0NraijVr1qCsrOz2D4joOng1V6IeUFBQgAkTJqCqqkruVoh6DHcxERGRXdyCICIiu7gFQUREdjEgiIjILgYEERHZxYAgIiK7GBBERGTX/weatw/QukFIrwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 67.65%\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "avail_device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device = torch.device(avail_device)\n",
    "\n",
    "vocab_size = len(train_data.vocab)\n",
    "emb_dim = 200\n",
    "num_filters = 200\n",
    "filter_sizes = [2, 3, 4, 5]\n",
    "output_dim = 2\n",
    "dropout = 0.2\n",
    "\n",
    "model = SentimentCNN(vocab_size, emb_dim, num_filters, filter_sizes, output_dim, dropout)\n",
    "\n",
    "# define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# train the model\n",
    "epochs = 50\n",
    "model.train()\n",
    "train_segment_pbar = tqdm()\n",
    "train_loader_len = train_data_loader.__len__()\n",
    "loss_data = []\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    train_segment_pbar.set_description(f'Training Epoch {epoch+1}/{epochs}')\n",
    "    train_segment_pbar.reset(total=train_loader_len)\n",
    "    for batch in train_data_loader:\n",
    "        train_segment_pbar.update()\n",
    "        optimizer.zero_grad()\n",
    "        text, label = batch\n",
    "        text = text.to(device)\n",
    "        label = label.to(device)\n",
    "        output = model(text)\n",
    "        loss = criterion(output, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    train_segment_pbar.refresh()\n",
    "    loss_data.append((epoch+1, running_loss/len(train_data_loader)))\n",
    "\n",
    "# plot the loss\n",
    "plt.plot(*zip(*loss_data))\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()\n",
    "\n",
    "# evaluate the model on test set\n",
    "correct = 0\n",
    "total = 0\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch in test_data_loader:\n",
    "        text, label = batch\n",
    "        text = text.to(device)\n",
    "        label = label.to(device)\n",
    "        output = model(text)\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        total += label.size(0)\n",
    "        correct += (predicted == label).sum().item()\n",
    "print(f'Accuracy on test set: {100 * correct / total:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), raw_data.joinpath('model.pt'))\n",
    "torch.save(train_data.get_vocab(), raw_data.joinpath('vocab.pt'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment predictions\n",
    "My overall approach here is to get the sentiment values of each word by training the model to correctly guess the `voted_up` field and develop the necessary coeffecients to do so. \n",
    "\n",
    "The process to extract their coeffients involves the following steps:\n",
    "   1. The input text is first tokenized using the basic_english tokenizer from torchtext.\n",
    "   1.  The tokenized text is then converted to numerical form by mapping each token to its corresponding index in the vocabulary.\n",
    "   1.  The numericalized tokens are then padded to a fixed length to ensure that all inputs have the same shape.\n",
    "   1.  The padded numericalized tokens are passed through the embedding layer of the model to obtain their corresponding word embeddings.\n",
    "   1.  The mean embedding for each review is calculated by taking the element-wise product of the embedding tensor and a binary mask tensor (which is 1 for tokens that are present and 0 for tokens that are padded) and then taking the mean along the sequence dimension.\n",
    "   1.  The mean embeddings are passed through a 1D convolutional layer (model.convs[0]), followed by a non-linear activation function (torch.tanh).\n",
    "   1.  The output of the convolutional layer is a 3D tensor with shape (batch_size, num_filters, seq_len - filter_size + 1).\n",
    "   1.  The tensor is then squeezed along the third dimension (i.e., `output = output.squeeze(3)`), resulting in a 2D tensor with shape ( `batch_size, num_filters, seq_len - filter_size + 1`).\n",
    "   1.  The tensor is then averaged along the third dimension (i.e., `output = output.mean(dim=2)`), resulting in a 2D tensor with shape (`batch_size, num_filters`).\n",
    "   1.  The tensor is then squeezed along the first dimension (i.e., `output = output.squeeze()`), resulting in a 1D tensor with shape (`num_filters,`).\n",
    "   1.  The final sentiment score for each review is obtained by taking the hyperbolic tangent of the average of the values in the 1D tensor (i.e., `torch.tanh(output.mean())`). This forces the value between -1 and 1, resulting in the actual sentiment score of the word in context to the sentence.\n",
    "\n",
    "Then I take the resulting lists, and iteratively strip the NaN values from them, this will allow me to more effeciently process the list later once it is inside of the dataframe.\n",
    "Finally in the dataframe I take the average of the values of the words in the sentences to get the final sentiment score of the sentence, dropping the last set of NaN values for sentences that we can't produce a score for (due to lack of vocab across the sentence)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "\n",
    "def predict_sentiment(df, vocab):\n",
    "    # Tokenize the review text\n",
    "    tokenizer = torchtext.data.get_tokenizer('basic_english')\n",
    "    temp_df = df['review'].apply(tokenizer)\n",
    "    max_seq_len = max(map(len, temp_df))\n",
    "\n",
    "    # Convert the tokens to numericalized form\n",
    "    numericalized_tokens = torch.zeros((len(temp_df), max(map(len, temp_df))), dtype=torch.long)\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        for i, tokens in enumerate(executor.map(lambda x: x[:max_seq_len], temp_df)):\n",
    "            numericalized_tokens[i, :len(tokens)] = torch.tensor([vocab[token] if token in vocab else vocab['<unk>'] for token in tokens])\n",
    "\n",
    "    padded_tokens = numericalized_tokens.unsqueeze(1)\n",
    "\n",
    "    # Calculate the sentiment score based on the mean value of the word embeddings\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        model.convs.eval()\n",
    "        embeddings = model.embedding(padded_tokens)\n",
    "        mask = padded_tokens.ne(0).unsqueeze(-1).float()\n",
    "        mean_embeddings = embeddings.mul(mask).sum(dim=1).div(mask.sum(dim=1))\n",
    "        mean_embeddings = mean_embeddings.permute(0, 2, 1)\n",
    "        output = model.convs[0](mean_embeddings)\n",
    "        output = output.squeeze(2)\n",
    "        output = output.mean(dim=1)\n",
    "        output = output.view(output.shape[0], -1)\n",
    "        sentiment_scores = torch.sigmoid(output).squeeze().tolist()\n",
    "\n",
    "    # Return the sentiment scores as a new column in the dataframe\n",
    "    sentiments = []\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        futures = [executor.submit(lambda x: np.array(x, dtype=np.float32)[~np.isnan(x)].tolist(), review_sentiment) for review_sentiment in sentiment_scores]\n",
    "        concurrent.futures.wait(futures)\n",
    "        for future in futures:\n",
    "            sentiments.append(future.result())\n",
    "\n",
    "    return sentiments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "\n",
    "def batch_predict_sentiment(df, batch_size):\n",
    "    # Reset the index of the DataFrame\n",
    "    df = df.reset_index(drop=True)\n",
    "    vocab = train_data.get_vocab()\n",
    "    # Split the DataFrame into batches\n",
    "    num_batches = int(np.ceil(len(df) / batch_size))\n",
    "    batches = np.array_split(df, num_batches)\n",
    "\n",
    "    # Create a ThreadPoolExecutor with a maximum of 4 worker threads\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:\n",
    "        # Submit each batch to the executor and store the Future objects\n",
    "        futures = [executor.submit(predict_sentiment, batch, vocab) for batch in tqdm(batches, desc='Submitting Batches', total=num_batches)]\n",
    "        \n",
    "        # Wait for all the Future objects to complete and get their results\n",
    "        results = [future.result() for future in tqdm(concurrent.futures.as_completed(futures), desc='Getting Results', total=num_batches)]\n",
    "    \n",
    "    # Flatten the list of results\n",
    "    results = [sentiment for batch_sentiments in results for sentiment in batch_sentiments]\n",
    "        \n",
    "    # Return the results as a new column in the original DataFrame\n",
    "    df['sentiments'] = results\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.009001016616821289,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Submitting Batches",
       "rate": null,
       "total": 21,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1e0f6ee276f4d2fbda40c84ccc1d9d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Submitting Batches:   0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.33299899101257324,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Getting Results",
       "rate": null,
       "total": 21,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41fbe716e7974d5896d29bdc24132d86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Getting Results:   0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import cProfile\n",
    "temp_df = filtered_df\n",
    "batch_size = 5000\n",
    "temp_df = batch_predict_sentiment(temp_df, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95314127]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ids</th>\n",
       "      <th>recommendationid</th>\n",
       "      <th>voted_up</th>\n",
       "      <th>received_for_free</th>\n",
       "      <th>written_during_early_access</th>\n",
       "      <th>weighted_vote_score</th>\n",
       "      <th>review</th>\n",
       "      <th>sentiments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>99266</th>\n",
       "      <td>6910</td>\n",
       "      <td>115752306</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.614178</td>\n",
       "      <td>Lip smack</td>\n",
       "      <td>0.953141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5235</th>\n",
       "      <td>1119980</td>\n",
       "      <td>115978184</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.523810</td>\n",
       "      <td>Great game A prime example that a game does no...</td>\n",
       "      <td>0.953141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8730</th>\n",
       "      <td>614090</td>\n",
       "      <td>85475210</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.512579</td>\n",
       "      <td>Can you make beat em up work with one punch co...</td>\n",
       "      <td>0.950278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20742</th>\n",
       "      <td>949170</td>\n",
       "      <td>49702623</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.473567</td>\n",
       "      <td>Caveat Emptor</td>\n",
       "      <td>0.949970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36093</th>\n",
       "      <td>344300</td>\n",
       "      <td>48834720</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.485808</td>\n",
       "      <td>LAPS LAPS LAPS</td>\n",
       "      <td>0.936660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89930</th>\n",
       "      <td>1108750</td>\n",
       "      <td>109048125</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.673469</td>\n",
       "      <td>A very cool shooter for the first time I see a...</td>\n",
       "      <td>0.000373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72078</th>\n",
       "      <td>680330</td>\n",
       "      <td>42078533</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.597946</td>\n",
       "      <td>DO NOT BUY THIS YET very glitchy lighting and ...</td>\n",
       "      <td>0.000373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48058</th>\n",
       "      <td>285900</td>\n",
       "      <td>115948007</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.523810</td>\n",
       "      <td>this is a game</td>\n",
       "      <td>0.000373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6443</th>\n",
       "      <td>530950</td>\n",
       "      <td>42060452</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.655085</td>\n",
       "      <td>Well it s been 3 hours and I m done but I have...</td>\n",
       "      <td>0.000259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47638</th>\n",
       "      <td>1359090</td>\n",
       "      <td>115598817</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.655883</td>\n",
       "      <td>The Devs</td>\n",
       "      <td>0.000204</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100475 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           ids  recommendationid  voted_up  received_for_free  \\\n",
       "99266     6910         115752306         1                  0   \n",
       "5235   1119980         115978184         1                  0   \n",
       "8730    614090          85475210         1                  0   \n",
       "20742   949170          49702623         0                  0   \n",
       "36093   344300          48834720         1                  0   \n",
       "...        ...               ...       ...                ...   \n",
       "89930  1108750         109048125         1                  0   \n",
       "72078   680330          42078533         0                  0   \n",
       "48058   285900         115948007         1                  0   \n",
       "6443    530950          42060452         1                  0   \n",
       "47638  1359090         115598817         1                  0   \n",
       "\n",
       "       written_during_early_access  weighted_vote_score  \\\n",
       "99266                            0             0.614178   \n",
       "5235                             0             0.523810   \n",
       "8730                             0             0.512579   \n",
       "20742                            0             0.473567   \n",
       "36093                            0             0.485808   \n",
       "...                            ...                  ...   \n",
       "89930                            0             0.673469   \n",
       "72078                            0             0.597946   \n",
       "48058                            0             0.523810   \n",
       "6443                             0             0.655085   \n",
       "47638                            1             0.655883   \n",
       "\n",
       "                                                  review  sentiments  \n",
       "99266                                         Lip smack     0.953141  \n",
       "5235   Great game A prime example that a game does no...    0.953141  \n",
       "8730   Can you make beat em up work with one punch co...    0.950278  \n",
       "20742                                     Caveat Emptor     0.949970  \n",
       "36093                                     LAPS LAPS LAPS    0.936660  \n",
       "...                                                  ...         ...  \n",
       "89930  A very cool shooter for the first time I see a...    0.000373  \n",
       "72078  DO NOT BUY THIS YET very glitchy lighting and ...    0.000373  \n",
       "48058                                    this is a game     0.000373  \n",
       "6443   Well it s been 3 hours and I m done but I have...    0.000259  \n",
       "47638                                          The Devs     0.000204  \n",
       "\n",
       "[100475 rows x 8 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(temp_df.head(1)['sentiments'].values)\n",
    "temp_df['sentiments'] = temp_df['sentiments'].apply(lambda x: np.mean(x))\n",
    "temp_df.dropna(inplace=True)\n",
    "temp_df.sort_values(by='sentiments', ascending=False, inplace=True)\n",
    "display(temp_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In review\n",
    "So in review I have made good strides in accomplishing part of my goal, and generating features for the dataset. However my downfall is a tandem of the effeciency of the code, and not performing more cleaning steps on the text (i.e not converting contractions to their long-form before stripping punctuation like apostrophes). Once some more of these steps are done and I am able to process the full dataset for training - I think the overall performance of the model will improve drastically. I definitely still have a lot more to learn about PyTorch and its associated libraries, but I am somewhat happy with how far I have come."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
