{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise\n",
    "This week the assignment is to take the `startups_profit.csv` file and perform a variety of tasks in order to achieve the desired results. These are as follows:\n",
    "1. Create a regression model that can predict profit\n",
    "2. Report relevant metrics for this type of model\n",
    "3. Tune Hyperparameters with cross-fold validation\n",
    "\n",
    "I intend on using PyTorch to become more famliar with the library and to aid the process of tuning my Semester Project to achieve the desired accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R&amp;D Spend</th>\n",
       "      <th>Administration</th>\n",
       "      <th>Marketing Spend</th>\n",
       "      <th>State</th>\n",
       "      <th>Profit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>165349.20</td>\n",
       "      <td>136897.80</td>\n",
       "      <td>471784.10</td>\n",
       "      <td>New York</td>\n",
       "      <td>$192,261.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>162597.70</td>\n",
       "      <td>151377.59</td>\n",
       "      <td>443898.53</td>\n",
       "      <td>California</td>\n",
       "      <td>$191,792.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>153441.51</td>\n",
       "      <td>101145.55</td>\n",
       "      <td>407934.54</td>\n",
       "      <td>FL</td>\n",
       "      <td>$191,050.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>144372.41</td>\n",
       "      <td>118671.85</td>\n",
       "      <td>383199.62</td>\n",
       "      <td>New York</td>\n",
       "      <td>$182,901.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>142107.34</td>\n",
       "      <td>91391.77</td>\n",
       "      <td>366168.42</td>\n",
       "      <td>FL</td>\n",
       "      <td>$166,187.94</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   R&D Spend  Administration  Marketing Spend       State         Profit\n",
       "0  165349.20       136897.80        471784.10    New York   $192,261.83 \n",
       "1  162597.70       151377.59        443898.53  California   $191,792.06 \n",
       "2  153441.51       101145.55        407934.54          FL   $191,050.39 \n",
       "3  144372.41       118671.85        383199.62    New York   $182,901.99 \n",
       "4  142107.34        91391.77        366168.42          FL   $166,187.94 "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd, numpy as np, torch, torch.nn as nn, torch.nn.functional as F, torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "base_path = Path()\n",
    "profit_file = base_path.joinpath('startups_profit.csv')\n",
    "profit_df = pd.read_csv(profit_file, skipinitialspace=True)\n",
    "profit_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transforming the data\n",
    "Before I subclass the datasets or build any models, first I want to transform the data how I need it to perform analysis. This involes the following steps:\n",
    "1. First I take the profit column of the data and strip all `$` or `,` characters by replacing them with nothing. During this process I reformat the data as a float value\n",
    "2. Next I create a copy of the original data - to preserve its integrity as I make further transformations.\n",
    "3. I scale the new dataframe on a standard curve - this gives me a reformatted set of columns that create a standard distribution. This will improve model accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sebas\\AppData\\Local\\Temp\\ipykernel_30056\\1392422914.py:1: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  profit_df['Profit'] = profit_df['Profit'].str.replace('[$,]', '').astype(float)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R&amp;D Spend</th>\n",
       "      <th>Administration</th>\n",
       "      <th>Marketing Spend</th>\n",
       "      <th>State</th>\n",
       "      <th>Profit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.016411</td>\n",
       "      <td>0.560753</td>\n",
       "      <td>2.153943</td>\n",
       "      <td>New York</td>\n",
       "      <td>2.011203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.955860</td>\n",
       "      <td>1.082807</td>\n",
       "      <td>1.923600</td>\n",
       "      <td>California</td>\n",
       "      <td>1.999430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.754364</td>\n",
       "      <td>-0.728257</td>\n",
       "      <td>1.626528</td>\n",
       "      <td>FL</td>\n",
       "      <td>1.980842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.554784</td>\n",
       "      <td>-0.096365</td>\n",
       "      <td>1.422210</td>\n",
       "      <td>New York</td>\n",
       "      <td>1.776627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.504937</td>\n",
       "      <td>-1.079919</td>\n",
       "      <td>1.281528</td>\n",
       "      <td>FL</td>\n",
       "      <td>1.357740</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   R&D Spend  Administration  Marketing Spend       State    Profit\n",
       "0   2.016411        0.560753         2.153943    New York  2.011203\n",
       "1   1.955860        1.082807         1.923600  California  1.999430\n",
       "2   1.754364       -0.728257         1.626528          FL  1.980842\n",
       "3   1.554784       -0.096365         1.422210    New York  1.776627\n",
       "4   1.504937       -1.079919         1.281528          FL  1.357740"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "profit_df['Profit'] = profit_df['Profit'].str.replace('[$,]', '').astype(float)\n",
    "scaled_df = profit_df.copy()\n",
    "numerical_columns = scaled_df.drop(columns=['State'])\n",
    "scaler = StandardScaler().fit_transform(numerical_columns)\n",
    "scaled_df[['R&D Spend', 'Administration', 'Marketing Spend', 'Profit']] = scaler\n",
    "\n",
    "scaled_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a dataset\n",
    "Before I can create a model, first I have to further transform the data to make it usable in PyTorch. This means I have to subclass the dataset. I did so in the following steps:\n",
    "1. First I created two values, an `X` value comprised of the spending columns and a `y` value comprised of the profit values\n",
    "2. Next I had to take the States column and encode it to numbers. I did this with a One-Hot encoding method to create a matrix of True (1) or False (0) values. \n",
    "3. Now that I have the matrix I don't need the state column so I drop it.\n",
    "4. Finally I have to transform them into the datatype that PyTorch uses, so I cast them into a tensor with a float datatype. \n",
    "\n",
    "#### Note\n",
    "In this class I have the `__len__` and `__getitem__` methods. These are needed for the dataset functions to subsection the data into the batches. It looks at the length of the dataset, and attempts to create equal length batches by looking at `__len__` then populates those batches by iterating over the dataset with `__getitem__`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the PyTorch dataset\n",
    "class ProfitDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.X = data[['R&D Spend', 'Administration', 'Marketing Spend']]\n",
    "        self.y = data['Profit'].values\n",
    "        \n",
    "        # Convert the categorical variable to one-hot encoding\n",
    "        states = pd.get_dummies(data['State'])\n",
    "        self.X = pd.concat([data, states], axis=1).drop(columns=['State']).values\n",
    "        # Convert the data to PyTorch tensors\n",
    "        self.X = torch.tensor(self.X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(self.y, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_data, test_data = train_test_split(scaled_df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Instantiate the datasets and dataloaders\n",
    "train_dataset = ProfitDataset(train_data)\n",
    "test_dataset = ProfitDataset(test_data)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=8, shuffle=True)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining the model\n",
    "Now that I have the dataset I have to create the model. The model is comprised of a few things, and as a whole is a subclass of the `nn.Module` class which represents all network models in PyTorch. There are two parts to this that I will cover in detail, the `__init__` portion and the `forward` porton.\n",
    "1. The `__init__` method defines the structure of the neural network. Each layer is outlined below:\n",
    "   1. `nn.Linear` is used to take the input features and produces an output according to the specific linear layer in question. `fc1` produces a number of outputs equal to the `hidden_size` whereas `fc2` takes the `hidden_size` and produces a number of outputs equal to the `output_size`\n",
    "   2. `nn.ReLU` is used to introduce non-linearity in the model. It does so by taking each element and applying the function `max(0,x)` to it. In a sense it replaces all negative values to zero and keeps all positive values unchanged. \n",
    "2. The `forward` method defines how the forward pass of the neural network will operate. In my case the following occurs:\n",
    "   1. `X` is passed through the first layer `self.fc1` to create our hidden layer, which is stored in the out.\n",
    "   2. The `out` tensor is then passed to the `self.relu` layer of the model, which is again stored in the out variable.\n",
    "   3. Lastly the `out` tensor is passed through the last linear layer `self.fc2` to produce the final output which is returned. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the PyTorch model\n",
    "class ProfitPredictor(nn.Module):\n",
    "\n",
    "    torch.manual_seed(42)\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(ProfitPredictor, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning Hyperparameters\n",
    "From here we need to get (approximately) the best hyperparameters for our data. Initally I attempted using sklearn GridSearch to do this, but wasn't able to get it to work properly with PyTorch, so instead I trained against each possible combination of hyperparameters and got the combination that yielded the least loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sebas\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([16])) that is different to the input size (torch.Size([16, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\Users\\sebas\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([8])) that is different to the input size (torch.Size([8, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: hidden_size=64, epochs=50, learning_rate=0.001\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "input_size = train_dataset.X.shape[1]\n",
    "\n",
    "# Define the hyperparameter search space\n",
    "hidden_sizes = [32, 64, 128]\n",
    "epochs = [50, 100, 200]\n",
    "learning_rates = [0.001, 0.01, 0.1]\n",
    "\n",
    "# Create a ProfitDataset object\n",
    "\n",
    "# Create a cross-validation object\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize empty lists to store the results\n",
    "val_losses = []\n",
    "best_params = []\n",
    "\n",
    "# Loop over all possible combinations of hyperparameters\n",
    "for hidden_size in hidden_sizes:\n",
    "    for num_epochs in epochs:\n",
    "        for lr in learning_rates:\n",
    "            \n",
    "            # Initialize the model with the current hyperparameters\n",
    "            model = ProfitPredictor(input_size=input_size, hidden_size=hidden_size, output_size=1)\n",
    "            \n",
    "            # Define the optimizer and the loss function\n",
    "            optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "            criterion = nn.MSELoss()\n",
    "            \n",
    "            # Initialize an empty list to store the validation losses\n",
    "            current_val_losses = []\n",
    "            \n",
    "            # Perform k-fold validation\n",
    "            for train_idx, val_idx in cv.split(train_dataset):\n",
    "                train_sub = torch.utils.data.Subset(train_dataset, train_idx)\n",
    "                val_sub = torch.utils.data.Subset(train_dataset, val_idx)\n",
    "                \n",
    "                train_loader = torch.utils.data.DataLoader(train_sub, batch_size=16, shuffle=True)\n",
    "                val_loader = torch.utils.data.DataLoader(val_sub, batch_size=16, shuffle=False)\n",
    "                \n",
    "                # Train the model on the current fold\n",
    "                for epoch in range(num_epochs):\n",
    "                    train_loss = 0.0\n",
    "                    for inputs, targets in train_loader:\n",
    "                        optimizer.zero_grad()\n",
    "                        outputs = model(inputs)\n",
    "                        loss = criterion(outputs, targets)\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                        train_loss += loss.item()\n",
    "                    train_loss /= len(train_loader)\n",
    "                    \n",
    "                    # Compute the validation loss for the current epoch\n",
    "                    with torch.no_grad():\n",
    "                        val_loss = 0.0\n",
    "                        for inputs, targets in val_loader:\n",
    "                            outputs = model(inputs)\n",
    "                            loss = criterion(outputs, targets)\n",
    "                            val_loss += loss.item()\n",
    "                        val_loss /= len(val_loader)\n",
    "                    current_val_losses.append(val_loss)\n",
    "            \n",
    "            # Compute the mean validation loss for the current hyperparameters\n",
    "            mean_val_loss = np.mean(current_val_losses)\n",
    "            \n",
    "            # Store the mean validation loss and the corresponding hyperparameters\n",
    "            val_losses.append(mean_val_loss)\n",
    "            best_params.append({'hidden_size': hidden_size, 'epochs': num_epochs, 'learning_rate': lr})\n",
    "\n",
    "# Find the hyperparameters with the lowest mean validation loss\n",
    "best_idx = np.argmin(val_losses)\n",
    "best_hidden_size = best_params[best_idx]['hidden_size']\n",
    "best_epochs = best_params[best_idx]['epochs']\n",
    "best_lr = best_params[best_idx]['learning_rate']\n",
    "print(\"Best hyperparameters: hidden_size={}, epochs={}, learning_rate={}\".format(best_hidden_size, best_epochs, best_lr))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train/Test Model\n",
    "Finally with out hyperparameters we will process the data against the model. In this case I also track the loss and plot it when its done to get an idea of the loss with this parameters.\n",
    "In the testing section I also extract all data, including the predictions, into a dataframe for viewing and calculating the R2 score afterwards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAAEKCAYAAAAYd05sAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/P9b71AAAACXBIWXMAAAsTAAALEwEAmpwYAAAlFElEQVR4nO3dd3hUZcI28HtaOgklDUiYhCqdGBJDU0EFMSCoKKyILvDGXVQEFhcQ128t++6rr/ohruUTRARpghAJYijSQUgmpJAGhBAgEFKo6ZPMzPP9MWSoIYHk5EzO3L/req7pc+7DFe85PnPmHBUAASIiUhy13AGIiEgaLHgiIoViwRMRKRQLnohIoVjwREQKxYInIlIoSQvey8sL69atQ2ZmJjIyMhARESHl4oiI6AZaKd984cKF2LJlC55//nnodDq4ublJuTgiIrqBChL90MnT0xPJycno2LGjFG9PRER1kGwLPjg4GEVFRVi6dCn69u2Lw4cPY8aMGSgvL6/1NYWFhTh9+rRUkYiIFEev18PX17fWx4UUIzQ0VFRXV4vw8HABQHz++efigw8+uO15UVFRwmAwCIPBIHJyciTJwsHBwaHUYTAY7va4NAv18/O7qbAHDx4sfv3114YE5eDg4OC4ZdytNyXbi6agoAC5ubno2rUrAOCxxx5DRkaGVIsjIqJbSLoXzfTp07Fy5Uo4OTnh5MmTmDx5spSLIyKiG0ha8CkpKQgLC5NyEUREVAv+kpWISKFY8ERECsWCJyJSqGZf8FonJzz654noOoBz/UREN2r2BW+ursajf34RoaNHyh2FiMiuNPuCF0IgKy4BXSO4BU9EdKNmX/AAkHXQAE8fb/h35oHNiIhqKKLgjx8yAAC6DgiXOQkRkf1QRMFfyS9AYc5pdInoL3cUIiK7oYiCB4CsuAR06h8CjVbSH+cSETUbiin44wfj4ezmBn3fXnJHISKyC4op+BOGRFjMZnTh3jRERAAUVPCVJaU4k5bBHzwREV2jmIIHgKxDCejQqwdcPNzljkJEJDtFFfzxg/FQazToHB4qdxQiItkpquBPp6TBWF7OeXgiIiis4M0mE7ITknjYAiIiKKzgAes8vG+wHi39/eSOQkQkK8UVfM1hC/irViJydIor+PysbBRfuMjj0hCRw1NcwQNA1iEDujzUHyqVSu4oRESyUWTBHz9oQIs2reHfpZPcUYiIZKPMgq85fDD3piEiB6bIgi8uLEJ+dg7n4YnIoSmy4AHrPHzH0H7Q6HRyRyEikoViC/74QQOcXF0Q1K+33FGIiGQh6dkxcnJyUFJSArPZDJPJhLCwppsTz05IhNlkQteIMGQbEptsuURE9kLyLfihQ4ciJCSkScsdAIxl5ThzJB3dBkc06XKJiOyFYqdoACB9z34E9ngALf185Y5CRNTkJC14IQS2bduGhIQEREVFSbmoO0rbuRcA0HPYw02+bCIiuUk6Bz948GDk5eXBx8cH27dvx9GjR7Fv376bnhMVFYVXX30VAODt7d2oyy86dQYFJ0+h19AhOLD650Z9byIieyfpFnxeXh4AoKioCNHR0QgPv32/9MWLFyMsLAxhYWG4cOFCo2dI27kXnfo/CFfPFo3+3kRE9kyygndzc4OHh4ft+vDhw5GWlibV4mqVtmsvNDotug8Z0OTLJiKSk2QF7+fnh/379yM5ORnx8fHYvHkztm7dKtXiapWbmoHiogvoNeyRJl82EZGcJJuDz8nJQb9+/aR6+3oTQiBt1z6EjhoBrZMTTFVVckciImoSit5Nskbazr1wdnND54d4Mm4ichwOUfAn4g+jsrQMvbi7JBE5EIcoeHN1NY7uP4heQx+GSu0Qq0xE5BgFD1inaVq0aQ19755yRyEiahIOU/CZ+/6Aqbqa0zRE5DAcpuArS8uQHX+YBU9EDsNhCh4A0nbtg09QB/gG6+WOQkQkOYcq+PTd1uPg8EdPROQIHKrgrxYU4UxqBqdpiMghOFTBA9a9afR9esLTp3GPXElEZG8cr+B3XTtG/KNDZE5CRCQthyv4guwcFJ3O5TQNESmewxU8AKTv2ofOD4XCydVV7ihERJJxyII/uv8gtDodOofz4GNEpFwOWfAnE1NgLK9At0EPyR2FiEgyDlnw5upqZCckottAFjwRKZdDFjwAHDsQBx99IFoHtJM7ChGRJBy34P+IAwBuxRORYjlswRedOoNL587jAc7DE5FCOWzBA9at+M7h/aHWauSOQkTU6By74A8cgouHO4L69pY7ChFRo3Pogs+KS4DZZOI8PBEpkkMXfGVpGc4cSef+8ESkSA5d8ABw9MAhtO/eDe6tWsodhYioUTl8wR87EAe1Wo2uA8LljkJE1KgcvuDPZh5D2eUrnIcnIsWRvODVajUSExOxadMmqRd1X4TFguMH49FtILfgiUhZJC/4GTNmIDMzU+rFNMixP+Lg6eONtl07yx2FiKjRSFrw7du3R2RkJL777jspF9Ngx/6IBwD+qpWIFEXSgv/8888xZ84cWCwWKRfTYMVFF5B3/AS6DYyQOwoRUaORrOAjIyNRWFiIxMTEuz4vKioKBoMBBoMB3t7ynQj72IE4BD/YB06uLrJlICJqbEKK8e9//1vk5uaKnJwccf78eVFWViZ+/PHHu77GYDBIkqU+o0tEmPgs9aDoPmSgbBk4ODg47nXcrTcl24KfP38+AgMDERwcjAkTJmDnzp2YNGmSVItrsJzEFFRVVPJXrUSkGA6/H3wNU1UVz/JERIrSJAW/Z88ejB49uikW1SDHDsTBN1iPNgHt5Y5CRNRg3IK/QeqOPQCAkKeekDkJEVHDseBvcCW/AFlxCeg/eqTcUYiIGowFf4vDm2LhE9QBHfr0lDsKEVGDsOBvcWT7blRVVCLs6afkjkJE1CB1FvzAgQPh5uYGAJg4cSI+++wzdOjQQfJgcjGWlyN1x270G/k4NDqd3HGIiO5bnQX/zTffoLy8HH369MHs2bORnZ2N5cuXN0U22STExMLN0xM9HhkkdxQiovtWZ8GbTCYAwJgxY/Dll1/i66+/RosWLSQPJqesuARcLSxC/6f5ZSsRNV91FnxJSQnmzZuHl156CZs3b4ZKpYJO4VMXwmJB4q9b0X3wQJ7Kj4iarToLfvz48TAajZg6dSoKCgoQEBCATz75pCmyySphUyw0Oi1CRj4udxQiovtSry34hQsXYv/+/ejSpQv69euH1atXN0U2WeWfOImzGccQyn3iiaiZqrPg9+7dC2dnZ7Rr1w7btm3DpEmT8MMPPzRBNPklbIpFh1494NcxSO4oRET3rM6CV6lUqKiowLPPPouvv/4aL7zwAnr16tUU2WSXFLsNZpOJW/FE1CzVq+AjIiIwceJEbN682foitWP8Pqr04mUcOxCH0FEjoHKQdSYi5aiztWbOnIm3334b0dHRyMjIQHBwMHbt2tUU2exCwqZYtPT3Q+ewB+WOQkR0z+p11hB3d3fh7u4u25lJ5BpaZ2fxrwPbxIR/vSt7Fg4ODo5bR4PO6NSrVy8kJiYiPT0dGRkZSEhIQI8ePep6mWKYjEYkb9uBPk88CidXV7njEBHVW50F/+233+Jvf/sbgoKCoNfrMXv2bCxevLgpstmNwzGxcHZzQ+/HH5U7ChFRvdVZ8O7u7ti9e7ft9p49e+Du7i5lJruTk3QEF3LPImwMjzBJRM1HnQV/8uRJ/OMf/4Ber4der8c777yDkydPNkU2u2LY+Bu6PNQfrdr5yx2FiKhe6iz4KVOmwMfHBxs2bMCGDRvg4+ODKVOmNEU2u5Kw8TdYLBYeJ56Img1tXU+4cuUKZsyY0RRZ7NqV/AKciD+M/mOewvZvl0IIIXckIqK7qrXgY2Ji7lpiY8aMkSSQPTP88ismfvQ+Oob2Q3ZCktxxiIjuqtaC//TTT5syR7OQumMPKkpKETY2kgVPRHav1oLfu3dvU+ZoFqorjUje+jsefGoEov/9f2EsL5c7EhFRrXiAlXtk+GUznN1c0Wf4ULmjEBHdFQv+Hp1OSUNhzmmEjY2UOwoR0V1JVvDOzs6Ii4tDcnIy0tLS8N5770m1qCZn2LgZnUJD0CYwQO4oRES1qnM3yTvtTXP16lUkJCTg22+/hdFovOPrjEYjhg0bhrKyMmi1Wuzfvx+xsbGIi4trnOQySti0BSOn/wVhY57Cli8XyR2HiOiO6vVL1tLSUixevBiLFy9GcXExSkpK0LVr1zqPSVNWVgYA0Ol00Ol0itl3vLiwCMcOxqP/0yN5nHgismt3PRRlfHx8rfelpaXd9bVqtVokJSWJkpIS8dFHHzXosJf2NvqNeEx8lnpQdIkIkz0LBweH444GHS7Yw8MDgYGBttuBgYHw8PAAAFRVVd31tRaLBSEhIQgICEB4eDh69ux523OioqJgMBhgMBjg7e1dVxy7kbZrH8qLixHOL1uJyE7VOQc/e/Zs7N+/H9nZ2VCpVAgODsZrr70GNzc3LFu2rF4LuXr1Knbt2oUnn3wS6enpNz1WM/UDAAaD4T5WQR6mqiok/bYd4WNHwcXDHZWlZXJHIiK6TZ3/C+Dk5CT69Okj+vTpI5ydnev1vw3e3t7Cy8tLABAuLi5i7969IjIy8r7/V8MeR2DP7uKz1IMiYtwY2bNwcHA45rhbb9a5BQ8AoaGhCAoKglarRd++fQEAP/74411f07ZtWyxbtgwajQZqtRpr1661nbRbKXLTM3E+Kxvhz4zGoZ83yh2HiOgmdRb88uXL0alTJyQnJ8NsNgMAhBB1FnxqaioefFD5J6qOWx+DsfNmoW3Xzjh//ITccYiIbOos+P79+zvUOVjvVcKmLYic9Roixo1B9L8/kzsOEZFNnXvRpKWlwd+fZzGqTUVxMY5s34XQyBHQuTjLHYeIyKbOLXhvb29kZGQgPj7+pl+tOuLx4GtzaH0MQkc9ib7DH0NCzG9yxyEiAlCPglfSMWSkcjIhCYU5pxHx3NMseCKyG3UWPI8LXz9x62Mw+q3p8OsUjILsHLnjEBHVPge/b98+AEBxcTGuXr1qGzW36WaGmN9gqq7GQ889LXcUIiIAdyn4IUOGAAA8PT3h5eVlGzW36WZll68gbcce9B89ElonJ7njEBHV73jwarUabdu2RWBgoG3Q7Q6tj4F7Sy/0fvxRuaMQEdU9B//GG2/gn//8JwoKCmCxWABYf+hU84tWuu5EXAIu5J5FxHNPI+m3bXLHISIHV2fBz5gxA926dcOlS5eaIk+zJoRA3PpNiJw5Dd76QFw4nSt3JCJyYHVO0eTm5vJL1Xtg+OVXmKtNiHiWX7YSkbzq3II/efIkdu/ejc2bN9/0Q6cFCxZIGqy5Krl4Cel79qP/mKcQ+59vYTaZ5I5ERA6qzi34M2fOYPv27XByckKLFi1sg2p36OeNaNGmNXoOe1juKETkwOrcgv/ggw+aIoeiHD8Yj0t55zHw+WdwZNtOueMQkYOqteAXLFiAWbNmISYm5o4ny+axaGonLBYcWPUzRr81HR369MSZI+l1v4iIqJHVWvA1x3v/9NNPmyyMkvyxdgOGTnkJw6dNxXfT/iZ3HCJyQLUWfGJiIgAei+Z+VVVUYveyVRg163UE9uqB3LQMuSMRkYOp80vWzp07Y926dUhPT0d2drZtUN3+WLMBZVeuYvi0KXJHISIHVGfBL126FN988w1MJhOGDh2K5cuXY8WKFU2Rrdkzlpdjz7LV6PHwIAT0eEDuOETkYOoseFdXV+zcuRMqlQpnzpzB+++/j8jIyKbIpgj7V69D+dViDP8rt+KJqGnVWfBGoxEqlQpZWVl4/fXXMXbsWHh4eDRFNkUwlpVjz/LV6Dl0CNp37yp3HCJyIHUW/IwZM+Dm5oY333wToaGheOmll/DKK680RTbF2L9qHcqLuRVPRE3rrgWvVqsxfvx4lJWV4dy5c5gyZQrGjRuHuLi4psqnCJWlZdj340/oNewRtOvWRe44ROQgai14jUYDi8WCwYMHN2Uexdq7ci0qikvwxF8myx2FiBxErfvBx8fHIzQ0FElJSdi4cSPWrVuHsrIy2+PR0dFNElApKktKsW/lWgyfNhVtu3bC+ePc1ZSIpFXnHLyLiwsuXryIYcOGYdSoURg9ejRGjRrVFNkUZ++Kn1BZWoYn/sK5eCKSXq1b8L6+vpg1axbS0tIghIBKpbI9dqdj09wqICAAy5cvh5+fH4QQWLRoEb744ovGSd1MVRSXYN+qtXji1cnwDdajMOe03JGISMHuOgfv4eEBDw8PtGjRwna9ZtTFZDJh9uzZ6NmzJyIiIvD666+je/fujRq+Odq3Yi2qKioxdPJLckchIoWrdQv+/Pnz+PDDD+/7jfPz85Gfnw8AKC0tRWZmJtq3b4/MzMz7fk8lKLt8BfHRmxDx/Fhs/WoxrhQUyh2JiBSq1i34G6dkGkqv1yMkJIS7V16ze9kqqFQqPPzyBLmjEJGC1Vrwjz32WKMswN3dHevXr8fMmTNRUlJy2+NRUVEwGAwwGAzw9vZulGXau8t5+UiK3Y6IcWPg6ukpdxwiUjAh1dBqtWLLli1i1qxZ9Xq+wWCQLIu9Df8uncRnqQfF43+ZLHsWDg6O5jvu1pt17ibZEEuWLEFmZiZP0H0H+VnZyNhzAENefB46F2e54xCRAklW8IMGDcLLL7+MYcOGISkpCUlJSRg5cqRUi2uWdi5ZDo/WrRD+zGi5oxCRAtV50u37deDAgUb9olaJcpKOICfpCB595UUcXBcNi8ksdyQiUhBJp2iobjuX/IjW7dui34jG+VKbiKgGC15mmXsP4HxWNoZNfVnuKESkMCx4mQkhsGvpSrTt0gndhwyUOw4RKQgL3g4kxW7D5fP5GDqVhy8gosbDgrcDFpMZu39YhU6hIeg28CG54xCRQrDg7cShnzeiMOc0nn9vHpzd3eSOQ0QKwIK3E6aqKqz+x4fw8vXB6NnT5Y5DRArAgrcjZ46kY8/yNRjw/Fh0HRAmdxwiauZY8HZmy1eLUZhzGi+8P59TNUTUICx4O2MyGjlVQ0SNggVvh84cSceeZas5VUNEDcKCt1Nbvv6OUzVE1CAseDvFqRoiaigWvB3jVA0RNQQL3s5t+WoxCk6e4lQNEd0zFrydM1VVYc27/7JO1bzFqRoiqj8WfDNgm6oZNxZdB4TLHYeImgkWfDNxfarmbU7VEFG9sOCbCVNVFdbU7FXDqRoiqgcWfDNyJjUDu5et4lQNEdULC76Z2frVd7apGhcPd7njEJEdY8E3MzdN1fAHUER0Fyz4ZqhmqiZi3Bh0GxQhdxwislMs+GZq61ffIf/ESUz86D14dwiQOw4R2SEWfDNlqqrC99PnQFgsiPpmAdxbtZQ7EhHZGRZ8M3bx7Dl8/+YcePn5YMoX/wuts7PckYjIjkhW8EuWLEFBQQFSU1OlWgQBOJ2ShlVvv4+gfr3xp/9+FyqVSu5IRGQnJCv4H374AU8++aRUb083OLJ9FzZ9+h/0G/EYnpo5Te44RGQntFK98b59+6DX66V6e7rF7mWr0DqgHYZNmYSLZ/NwaN0vckciIplJVvDU9H75aAFatfPHs/Nn48r5fBzdf0juSEQkI9m/ZI2KioLBYIDBYIC3t7fccZo1i9mMH996F+ePZ2PSp/+Cf+eOckciIhnJXvCLFy9GWFgYwsLCcOHCBbnjNHtVFRVYMv3vMJaVY8p/PuHuk0QOTPaCp8ZXXFiEpW/Ohad3G/x5wf9Ao9PJHYmIZCBZwa9atQoHDx5Et27dkJubiylTpki1KLqD3PRMrP7Hh+gY2g/j/s8cueMQkQwk+5L1xRdflOqtqZ5Stu7A1o5BGPHaf6Eg+xR2/7BS7khE1IS4F43Cbf9/38OvYxAiZ72GwpzTyNizX+5IRNREOAevcEIIrHn3XzibcRQTP34Pbbt2kjsSETURFrwDqK40Yumbc2EsLcfULz9FYM/uckcioibAgncQxUUXsOSNtwAA01cswvBpU6HWamRORURSYsE7kHNHj+PT5yYh6bftGPHaf2H6j4vgG8zDSRApFQvewVSWlGL1Ox/gh1lvo037dvjb2mUYMvEFHoWSSIFY8A4q9ffd+OSZiciKT8DYebPw6qKFaOnvJ3csImpELHgHVnLxEpa8/hbWvvc/0Pfpibc2rEDY2Ei5YxFRI2HBE+LWx+DT5yYh71gWJnz4D0z5zydo4d1G7lhE1EAseAIAXDqbh2+mvI5fPv4cXSPC8Pfolej35ONyxyKiBmDBk40QAvtW/ITPnn8ZF07nYtInH+Llz/4bLdq0ljsaEd0HFjzdpujUGXz5yl+x+fOv0XPoELyzZQPGzJkJTx8er5+oOWHB0x1ZzGbsXPIj/nfMi0jash2D/vQc5sf+jGfmz4aXn4/c8YioHlQAhNwhahgMBoSFhckdg+6gdUA7PDb1ZYSNiYQQFsRH/4pdS1fg0rnzckcjcmh3600WPN2TVm39MWzqJIQ/OxpqjQYZe/Zj/6qfkXXIIHc0IofEgqdG5+nrg4Hjn0HEc2PQok1rFJw8hQOrf0ZCTCyM5eVyxyNyGCx4koxGp0O/EY9h8IvPo0PvHqgsLUPib9uQvnsfTsQnwmQ0yh2RSNHu1ps84Qc1iLm6God/3YLDv25BYK8eGPziOISOehIDX3gG1ZVGZMUnIHPvH8jc9wcu5+XLHZfIoXALnhqd1skJHUP7ofvDA9Hj4UHw7hAAACg4eQonE5NxKikVp5KP4MKZszInJWr+OEVDsvLWB6LHw4PQdUAY9H17wc3TE4D1WDinU1JxKjkV50+cRNGpXFzOOw+L2SxzYqLmgwVPdkOlUsG3YxCC+vVGcEgfBPXtDZ+gDrbHzdUmXDx7DkWnzqDw1BlcPHsOl86dx6Vzebiclw9TVZWM6YnsD+fgyW4IIVCQnYOC7BzErY8BALh6esI3uAN8gzrAW98BPvpA+AR1QNcB4dC5ON/0+qsFRbh0Lg9X8gtQevmKdVy6jLJLl1F6+QrKLl9BZWkZKkpKUF3JL3jJsbHgSXYVxcU4nZKG0ylpN92vUqnQwscbbdq3Rev27dA6oB1aX7se0LM7PFq1hKtni1rf11xtQmVpKSpKS1FRUoqKq8Uov1qMsitXUV5svV5xtRjG8gpUVxpRbTSiqrLSer2yElU1l+UVMJtMUv8zEDU6FjzZLSEEiguLUFxYhJykI3d8jkang3urlvBo1RIerVvCvWVLuHh4wKWFO1w8PODawgMuHu5wbdECbl6eaOnvBzcvT7h5eUKtqf85ac0mE6oqKlFVUXH9srwCVRUVMFZU2q6bqqphqjLCVFWNamMVTFXWUW00wmS0XlYba24brz2/CuZqE0zVVTBVVcNcXW27FMJuZlCpGWLBU7Nmrq62fQjcC5VKBWd3N7h5ecLJ1RU6Z2foXF2sl87OcHJ1hs7FBU6urnBydYHTjdfdrJfOrm5w8fCAp6+P7TGtkxN0zk7QOjk1zvqZTDBXm6ylX20t/Rs/OEzGKlTXXL/lw8FUff3D4/rrTdfvM1nvv35pvn772rDUXK82wWwyX7994+PX3ovsDwueHJIQApWlZagsLZPk/VUqFTQ6HbROOuicna3F72L98NA6O9k+SGqeU3Op1emgqbnU6aDRaaHVOV271EHr5GR9npOT9X2cnKFzcoJrCw9onZyg0Wqtlzqt7bk190nNWvjm6+VvNt90n8Vstt5XfcNjZvMtj1/7IDHfMExmmM13+nC5+T0sZjMsFsu16zXvZ7Eu66bnmCEsAuLaZc3rhNkCi8V80+tuHtfvM5vMEJZr91ksEDXvYbFI/u98LyQt+BEjRmDhwoXQaDT47rvv8PHHH0u5OCK7IYSwbWVL9SFyrzRa7bUPDZ2t+K33XRta6weLWnftfq0GGq0WatvzbnyN5vr9Wi3UGs3167qb77c+Zn1+zfPUWg001x7TOung5OpivU+rhUqtvv5arQYajdb2mO3y2vvYI4vF+kEgzBaYr33QWK9bL4WwXPtgqLktUHLpEr7+82uNnkWyfyG1Wo2vvvoKTzzxBM6ePQuDwYCYmBhkZmZKtUgiuouaLV9UVMgdpVGoVCrbh4Bafe1So4H62geESqOGWmP9oFKp1bYPBet1NVQqNVRqFdRqte1x9bXXWC81N7+/7fFb77/++ppMKrXa+gF2bdk1H0o3Pm57nVot2UaAZAUfHh6OEydOICcnBwCwZs0ajBkzhgVPRI1CCHH9Q4vuSLITfrRv3x65ubm222fPnkX79u2lWhwREd1C9kmsqKgovPrqqwAAb2+eEo6IqLFItgV/7tw5BAYG2m4HBATg3Llztz1v8eLFCAsLQ1hYGC5cuCBVHCIihyNZwRsMBnTp0gVBQUHQ6XSYMGECYmJipFocERHdQrIpGrPZjDfeeANbt26FRqPB999/j4yMDKkWR0REt5B0Dj42NhaxsbFSLoKIiGoh2RQNERHJiwVPRKRQdnXCj8LCQpw+ffq+Xuvt7e2Qe+FwvR0L19ux1Ge99Xo9fH19a31cKGEYDAbZM3C9ud5cb663Pa03p2iIiBSKBU9EpFCKKfhFixbJHUEWXG/HwvV2LA1db7v6kpWIiBqPYrbgiYjoZs2+4EeMGIGjR48iKysLc+fOlTuOpJYsWYKCggKkpqba7mvVqhW2bduG48ePY9u2bWjZsqV8ASUQEBCAnTt3Ij09HWlpaXjzzTcBKH+9AcDZ2RlxcXFITk5GWloa3nvvPQBAUFAQDh06hKysLKxZswY6nU7eoBJQq9VITEzEpk2bADjGOgNATk4Ojhw5gqSkJBgMBgAN/1uXfVeg+x1qtVqcOHFCBAcHC51OJ5KTk0X37t1lzyXVGDJkiAgJCRGpqam2+z7++GMxd+5cAUDMnTtXfPTRR7LnbMzh7+8vQkJCBADh4eEhjh07Jrp376749a4Z7u7uAoDQarXi0KFD4qGHHhI//fSTGD9+vAAgvvnmG/HXv/5V9pyNPWbNmiVWrlwpNm3aJAA4xDoDEDk5OaJNmzY33dfAv3X5V+p+R0REhNiyZYvt9rx588S8efNkzyXl0Ov1NxX80aNHhb+/vwCsZXj06FHZM0o5fvnlF/H444873Hq7urqKw4cPi/DwcFFUVCQ0Go0Abv9vQAmjffv24vfffxdDhw61FbzS17lm3KngG/K33qynaHjWKMDPzw/5+fkAgPz8fPj5+cmcSDp6vR4hISGIi4tzmPVWq9VISkpCYWEhtm/fjuzsbFy5cgVmsxmAMv/mP//8c8yZMwcWiwUA0KZNG8Wvcw0hBLZt24aEhARERUUBaNh/47Kf0YkalxBC7giScHd3x/r16zFz5kyUlJTc9rhS19tisSAkJAReXl6Ijo7GAw88IHckSUVGRqKwsBCJiYl45JFH5I7T5AYPHoy8vDz4+Phg+/btOHr06G3PuZe/9WZd8PU9a5SSFRQUwN/fH/n5+fD390dhYaHckRqdVqvF+vXrsXLlSkRHRwNwjPW+0dWrV7Fr1y4MGDAALVu2hEajgdlsVtzf/KBBg/D000/jqaeegouLCzw9PbFw4UJFr/ON8vLyAABFRUWIjo5GeHh4g/7Wm/UUDc8aBcTExOCVV14BALzyyivYuHGjzIka35IlS5CZmYkFCxbY7nOE9fb29oaXlxcAwMXFBU888QQyMzOxa9cujBs3DoDy1n3+/PkIDAxEcHAwJkyYgJ07d+Kll15S9DrXcHNzg4eHh+368OHDkZaW1uC/ddm/WGjIGDlypDh27Jg4ceKEmD9/vux5pByrVq0SeXl5oqqqSuTm5oopU6aI1q1bi99//10cP35cbN++XbRq1Ur2nI05Bg0aJIQQIiUlRSQlJYmkpCQxcuRIxa83ANG7d2+RmJgoUlJSRGpqqnj33XcFABEcHCzi4uJEVlaWWLt2rXBycpI9qxTjkUcesX3J6gjrHBwcLJKTk0VycrJIS0uz9VlD/tb5S1YiIoVq1lM0RERUOxY8EZFCseCJiBSKBU9EpFAseCIihWLBk+KZTCYkJSXZRmMedVSv1990dE8ie9Ksf8lKVB8VFRUICQmROwZRk+MWPDmsnJwcfPzxxzhy5Aji4uLQqVMnANat8h07diAlJQW///677XAYvr6+2LBhA5KTk5GcnIwBAwYAADQaDRYtWoS0tDRs3boVLi4uAIDp06cjPT0dKSkpWL16tTwrSQ5P9l9wcXBIOUwmk+1XsElJSeKFF14QgPXQrDW/Fpw0aZLtV5MxMTHi5ZdfFgDE5MmTRXR0tAAg1qxZI2bMmCEA67kIPD09hV6vF9XV1aJv374CsB63fOLEiQKAOHfunO0Xl15eXrL/O3A45JA9AAeHpKOkpOSO9+fk5Ijg4GABWE+oceHCBQFYjz2u1Wpt9xcVFQkAorCw8LafyOv1enH8+HHb7Tlz5oh33nlHABCxsbFi3bp1YuLEibYTd3BwNOXgFA05tBsPvXq/hxw2Go2262azGVqt9autyMhIfPXVV3jwwQdhMBig0WgaFpboHrHgyaGNHz/ednnw4EEAwB9//IEJEyYAACZOnIh9+/YBAHbs2IFp06YBsJ6Iw9PTs9b3ValUCAwMxO7duzF37lx4eXnZjhRI1FS4Fw0pnqurK5KSkmy3t2zZgrfffhuA9YTGKSkpMBqN+NOf/gTA+uXo0qVL8fe//x1FRUWYPHkyAGDGjBlYtGgRpk6dCrPZjGnTpuH8+fN3XKZGo8GKFSvg5eUFlUqFL774AlevXpV4TYluxqNJksPKyclB//79cfHiRbmjEEmCUzRERArFLXgiIoXiFjwRkUKx4ImIFIoFT0SkUCx4IiKFYsETESkUC56ISKH+Pxj20yKb6z+5AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the model parameters\n",
    "input_size = train_dataset.X.shape[1]\n",
    "hidden_size = 64\n",
    "output_size = 1\n",
    "lr = 0.001\n",
    "epochs = 50\n",
    "\n",
    "# Instantiate the model and the optimizer\n",
    "model = ProfitPredictor(input_size, hidden_size, output_size)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "loss_data = []\n",
    "# Train the model\n",
    "model.train()\n",
    "for epoch in range(epochs):\n",
    "    train_loss = 0.0\n",
    "    for X_batch, y_batch in train_dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(X_batch)\n",
    "        loss = criterion(y_pred.squeeze(), y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    loss_data.append(train_loss)\n",
    "\n",
    "plt.plot(range(epochs), loss_data)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Training loss')\n",
    "plt.show()\n",
    "\n",
    "pred_df = pd.DataFrame()\n",
    "# Evaluate the model\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_loss = 0\n",
    "    for X_batch, y_batch in test_dataloader:\n",
    "        y_pred_test = model(X_batch)\n",
    "        test_loss += criterion(y_pred_test.squeeze(), y_batch).item()\n",
    "        X_batch = X_batch.numpy()\n",
    "        y_batch = y_batch.numpy()\n",
    "        y_pred_test = y_pred_test.detach().numpy()\n",
    "\n",
    "        # Extract the state information from the one-hot encoding\n",
    "        states = ['California', 'Florida', 'New York']\n",
    "        state_idx = np.argmax(X_batch[:,3:6], axis=1)\n",
    "        state = [states[i] for i in state_idx]\n",
    "\n",
    "        # Add the results to the DataFrame\n",
    "        batch_df = pd.DataFrame({'R&D Spend': X_batch[:,0], 'Administration': X_batch[:,1], 'Marketing Spend': X_batch[:,2], 'State': state, 'Profit': y_batch, 'Predicted': y_pred_test[:,0]})\n",
    "        pred_df = pd.concat([pred_df, batch_df], ignore_index=True) \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results\n",
    "Now that I've trained and tested the data with the optimal parameters, it looks like we get an R2 score of approximately 0.95. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R&amp;D Spend</th>\n",
       "      <th>Administration</th>\n",
       "      <th>Marketing Spend</th>\n",
       "      <th>State</th>\n",
       "      <th>Profit</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.199312</td>\n",
       "      <td>0.656489</td>\n",
       "      <td>-0.603517</td>\n",
       "      <td>Florida</td>\n",
       "      <td>-0.115493</td>\n",
       "      <td>-0.053420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.773820</td>\n",
       "      <td>-1.383122</td>\n",
       "      <td>-0.297583</td>\n",
       "      <td>Florida</td>\n",
       "      <td>-0.777094</td>\n",
       "      <td>-0.765211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.279442</td>\n",
       "      <td>1.159837</td>\n",
       "      <td>-1.743127</td>\n",
       "      <td>California</td>\n",
       "      <td>0.269773</td>\n",
       "      <td>0.111597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.258074</td>\n",
       "      <td>-0.205629</td>\n",
       "      <td>-0.990357</td>\n",
       "      <td>New York</td>\n",
       "      <td>-0.302625</td>\n",
       "      <td>-0.334697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.035370</td>\n",
       "      <td>0.821718</td>\n",
       "      <td>-0.635835</td>\n",
       "      <td>New York</td>\n",
       "      <td>-0.157367</td>\n",
       "      <td>-0.043505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-1.610433</td>\n",
       "      <td>-2.509409</td>\n",
       "      <td>-1.743127</td>\n",
       "      <td>Florida</td>\n",
       "      <td>-1.913212</td>\n",
       "      <td>-1.503323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.460720</td>\n",
       "      <td>0.855666</td>\n",
       "      <td>0.591017</td>\n",
       "      <td>California</td>\n",
       "      <td>0.334771</td>\n",
       "      <td>0.466575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-1.600350</td>\n",
       "      <td>0.101254</td>\n",
       "      <td>-1.727400</td>\n",
       "      <td>Florida</td>\n",
       "      <td>-1.180082</td>\n",
       "      <td>-1.360597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.402078</td>\n",
       "      <td>0.510179</td>\n",
       "      <td>0.343957</td>\n",
       "      <td>Florida</td>\n",
       "      <td>0.558749</td>\n",
       "      <td>0.644234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.226949</td>\n",
       "      <td>0.283924</td>\n",
       "      <td>-1.362450</td>\n",
       "      <td>Florida</td>\n",
       "      <td>-0.365524</td>\n",
       "      <td>-0.332923</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   R&D Spend  Administration  Marketing Spend       State    Profit  Predicted\n",
       "0  -0.199312        0.656489        -0.603517     Florida -0.115493  -0.053420\n",
       "1  -0.773820       -1.383122        -0.297583     Florida -0.777094  -0.765211\n",
       "2   0.279442        1.159837        -1.743127  California  0.269773   0.111597\n",
       "3  -0.258074       -0.205629        -0.990357    New York -0.302625  -0.334697\n",
       "4   0.035370        0.821718        -0.635835    New York -0.157367  -0.043505\n",
       "5  -1.610433       -2.509409        -1.743127     Florida -1.913212  -1.503323\n",
       "6   0.460720        0.855666         0.591017  California  0.334771   0.466575\n",
       "7  -1.600350        0.101254        -1.727400     Florida -1.180082  -1.360597\n",
       "8   0.402078        0.510179         0.343957     Florida  0.558749   0.644234\n",
       "9  -0.226949        0.283924        -1.362450     Florida -0.365524  -0.332923"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score: 0.95\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "display(pred_df)\n",
    "r2 = r2_score(pred_df['Profit'], pred_df['Predicted'])\n",
    "print(f'R2 score: {r2:.2f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
